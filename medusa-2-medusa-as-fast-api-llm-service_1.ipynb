{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task is to implement a FastAPI service that serves a Language Model (LLM) with a [medusa](https://github.com/FasterDecoding/Medusa) head (using `lmsys/vicuna-7b`). The goal is to optimize the inference speed using a model compilation library (e.g., `llama.cpp`) and enhance performance via speculative decoding with the medusa head. Additionally, you are required to implement dynamic batching to handle multiple concurrent requests efficiently.\n",
    "\n",
    "### **Key Deliverables:**\n",
    "\n",
    "1. **Model Compilation:**\n",
    "    - Use a model compilation library (e.g., [llama.cpp](https://github.com/ggerganov/llama.cpp)) to optimize the inference of the base model.\n",
    "    - Provide an explanation of your choice of compilation library and its impact on performance.\n",
    "2. **Medusa Head Implementation:**\n",
    "    - Implement the medusa head on top of the base model to improve performance via speculative decoding. Avoid using existing implementations.\n",
    "    - Include a brief explanation of how speculative decoding is implemented and its advantages.\n",
    "3. **Dynamic Batching:**\n",
    "    - Implement dynamic batching to efficiently manage multiple concurrent requests.\n",
    "    - Explain your approach to dynamic batching and its benefits in serving LLMs.\n",
    "4. **Service Implementation:**\n",
    "    - Use [FastAPI](https://fastapi.tiangolo.com/) to create a service that serves the LLM with the medusa head.\n",
    "    - Ensure the service can handle concurrent requests with low latency.\n",
    "5. **Testing & Validation:**\n",
    "    - Provide test cases to validate the correctness and efficiency of your implementation.\n",
    "    - Include performance benchmarks or metrics comparing different configurations (e.g., with and without the medusa head, with and without dynamic batching).\n",
    "\n",
    "### **Resources:**\n",
    "\n",
    "- [llama.cpp GitHub Repository](https://github.com/ggerganov/llama.cpp): A popular model compilation library for LLMs.\n",
    "- [FastAPI Documentation](https://fastapi.tiangolo.com/): Official documentation for FastAPI.\n",
    "- [Hugging Face Model Hub: lmsys/vicuna-7b-v1.3](https://huggingface.co/lmsys/vicuna-7b-v1.3): The model you will be working with.\n",
    "- [Google Colab](https://colab.research.google.com/) and [Kaggle Notebooks](https://www.kaggle.com/kernels): Free resources to access GPUs for this project.\n",
    "\n",
    "### **Grading Criteria:**\n",
    "\n",
    "1. **Correctness (40%):**\n",
    "    - Functional service that correctly serves the LLM.\n",
    "    - Proper implementation of the medusa head with enhanced performance.\n",
    "2. **Optimization & Performance (30%):**\n",
    "    - Effective use of the model compilation library for inference optimization.\n",
    "    - Performance improvement through speculative decoding with the medusa head.\n",
    "    - Efficient handling of requests with dynamic batching.\n",
    "3. **Code Quality & Documentation (20%):**\n",
    "    - Clean, readable, and maintainable code.\n",
    "    - Clear and concise documentation explaining implementation choices.\n",
    "4. **Testing & Validation (10%):**\n",
    "    - Comprehensive test cases covering key functionalities.\n",
    "    - Inclusion of performance benchmarks or metrics to demonstrate optimizations.\n",
    "\n",
    "### **Partial Credit:**\n",
    "\n",
    "Partial implementations will still be evaluated based on relevant criteria. For instance:\n",
    "\n",
    "- **Model Optimization Only:** Focusing on base model optimization without medusa head or dynamic batching.\n",
    "- **Medusa Head Implementation:** Implementing speculative decoding without dynamic batching.\n",
    "- **Dynamic Batching:** Focusing on request handling efficiency without medusa head.\n",
    "\n",
    "---\n",
    "\n",
    "### **Additional Notes:**\n",
    "\n",
    "- **Free GPU Access:** If you need access to GPUs, consider using services like [Google Colab](https://colab.research.google.com/) or [Kaggle Notebooks](https://www.kaggle.com/kernels), which provide free access to GPU resources.\n",
    "- **Submission:** Please submit your code, along with a brief report (Markdown or PDF) explaining your implementation, testing, and any performance metrics.\n",
    "\n",
    "This assignment is designed to test your understanding of model optimization, complex inference strategies, and the ability to build scalable services. Partial implementations are welcome and will be graded accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EE_-hYiqr__R"
   },
   "source": [
    "# Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tun5_m6PuP0T",
    "outputId": "c00555e0-002a-43aa-f916-44c194c718e6"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/FasterDecoding/Medusa.git\n",
    "%cd Medusa\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_pvgGlUvCTo",
    "outputId": "058d0671-4da2-490f-d7ac-95dd57965c2d"
   },
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVhj8n8qhAtY",
    "outputId": "3c192740-e7f2-4e3f-ec4a-4978f3e257fc"
   },
   "outputs": [],
   "source": [
    "!pip install pyngrok sentencepiece\n",
    "# !pip install medusa-llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359,
     "referenced_widgets": [
      "4f2bedf81edd438db1e6c9a2aa41f232",
      "433c50d1f40442e39ab4e89756633ed2",
      "f7abca3d5824472e8efe63668cee5f8f",
      "ec133885fe2b419286ae609f52efbf59",
      "6b0f7d81472b4eaabb0325861c3e17d8",
      "29495f23ed974a9a9f54c06aee42708e",
      "b526e765ebfa410184392667c4ff7262",
      "a6950c1233bb4bb588ccc86961e2e907",
      "bf355ee0edf24dc18831d76ac9d39842",
      "9b1ecd205f02453b9a66535130d66185",
      "35e12a72c3d140aab8a45a289db88155",
      "4d55d82c57c445739214a38419f638a5",
      "9ffd8b1684444acd94294959214c3c28",
      "12b14e88bc09472897076dd6b8b62945",
      "81941dffdc6e4c90b77fc6cb6506a626",
      "d9f5552a9c0e42b09c96cb11bbad8b35",
      "9bda68f535524c5997e0d11d81fae635"
     ]
    },
    "id": "qY2ULRBMOM0P",
    "outputId": "b70a9f57-e639-41f6-ceaf-a8e19faa7d65"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T10:10:29.582171Z",
     "iopub.status.busy": "2025-03-28T10:10:29.581817Z",
     "iopub.status.idle": "2025-03-28T10:11:50.345999Z",
     "shell.execute_reply": "2025-03-28T10:11:50.345119Z",
     "shell.execute_reply.started": "2025-03-28T10:10:29.582140Z"
    },
    "id": "3MUE7jF_MZK5",
    "outputId": "e3c70327-bd45-4e53-8a7e-08a886790887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python==0.2.85\n",
      "  Using cached llama_cpp_python-0.2.85.tar.gz (49.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.85) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.85) (1.26.4)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.85)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.85) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.85) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.2.85) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.2.85) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.2.85) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.2.85) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.2.85) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.2.85) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20.0->llama-cpp-python==0.2.85) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20.0->llama-cpp-python==0.2.85) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20.0->llama-cpp-python==0.2.85) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20.0->llama-cpp-python==0.2.85) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20.0->llama-cpp-python==0.2.85) (2024.2.0)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.85-cp310-cp310-linux_x86_64.whl size=2873164 sha256=00443c2cf73398331ef51b22b7c0f952bc1e9fe53a4459631db430e9e5bea031\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e8/4e/29a754f9175ef52b6481cd75e3af4de38bf6dfa9c2972f75d4\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.85\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python==0.2.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:12:58.046617Z",
     "iopub.status.busy": "2025-03-28T10:12:58.046021Z",
     "iopub.status.idle": "2025-03-28T10:12:58.110847Z",
     "shell.execute_reply": "2025-03-28T10:12:58.110071Z",
     "shell.execute_reply.started": "2025-03-28T10:12:58.046565Z"
    },
    "id": "QgLsYyKRM5Ol"
   },
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ud3Ha0-rVFM-",
    "outputId": "31444739-6321-45a9-c04c-1a2af4f7c632"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.36.0 accelerate==0.25.0 huggingface_hub==0.20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZVqduA6FW0R"
   },
   "source": [
    "#### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:13:20.858140Z",
     "iopub.status.busy": "2025-03-28T10:13:20.857572Z",
     "iopub.status.idle": "2025-03-28T10:13:20.886699Z",
     "shell.execute_reply": "2025-03-28T10:13:20.886038Z",
     "shell.execute_reply.started": "2025-03-28T10:13:20.858106Z"
    },
    "id": "x-iqY91oCpGW"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import logging\n",
    "import asyncio\n",
    "from typing import List, Dict, Optional\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from pyngrok import ngrok\n",
    "import time\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from threading import Lock\n",
    "from contextlib import asynccontextmanager\n",
    "import uvicorn  # Ensure uvicorn is imported for server startup\n",
    "\n",
    "# For notebook environments\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Import Medusa components from the repository\n",
    "from medusa.model.medusa_model import MedusaModel\n",
    "from medusa.model.medusa_choices import mc_sim_7b_63  # Pre-defined Medusa choices\n",
    "from medusa.model.utils import generate_medusa_buffers, reset_medusa_mode, initialize_medusa\n",
    "from medusa.model.kv_cache import initialize_past_key_values\n",
    "from llama_cpp import Llama\n",
    "\n",
    "\n",
    "# Set up logging with human-written comments for clarity\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define request and response models\n",
    "class GenerationRequest(BaseModel):\n",
    "    prompt: str\n",
    "    max_length: int = 512\n",
    "    temperature: float = 0.7\n",
    "    posterior_threshold: float = 0.09\n",
    "    posterior_alpha: float = 0.3\n",
    "\n",
    "class GenerationResponse(BaseModel):\n",
    "    text: str\n",
    "    generation_time: float\n",
    "    tokens_generated: int\n",
    "    tokens_per_second: float\n",
    "    speedup_factor: Optional[float] = None\n",
    "\n",
    "@dataclass\n",
    "class BatchRequest:\n",
    "    id: str\n",
    "    prompt: str\n",
    "    timestamp: datetime\n",
    "    max_length: int = 512\n",
    "    temperature: float = 0.7\n",
    "    posterior_threshold: float = 0.09\n",
    "    posterior_alpha: float = 0.3\n",
    "\n",
    "class MedusaLlamaCppManager:\n",
    "    \"\"\"\n",
    "    Manager class that combines llama.cpp with Medusa for speculative decoding.\n",
    "    This class loads the model, sets up Medusa buffers, and provides text generation.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str = \"/kaggle/input/vicuna-1/gguf/default/1/vicuna-7b-v1.3-F16_KM.gguf\",\n",
    "        medusa_num_heads: int = 4,\n",
    "        n_ctx: int = 2048,\n",
    "        n_batch: int = 512,\n",
    "        n_threads: int = 8\n",
    "    ):\n",
    "        self.logger = logging.getLogger(\"MedusaLlamaCppManager\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.medusa_num_heads = medusa_num_heads\n",
    "        self.model_lock = Lock()  # For thread safety\n",
    "\n",
    "        # Load compiled model using llama.cpp backend\n",
    "        self.llama_model = Llama(\n",
    "            model_path=model_path,\n",
    "            n_ctx=n_ctx,\n",
    "            n_batch=n_batch,\n",
    "            n_threads=n_threads,\n",
    "            n_gpu_layers=-1\n",
    "        )\n",
    "        self.logger.info(f\"Loaded GGUF model from {model_path}\")\n",
    "\n",
    "        # Initialize Medusa components\n",
    "        self.medusa_choices = mc_sim_7b_63\n",
    "        self.medusa_buffers = self._initialize_medusa_buffers()\n",
    "        self.logger.info(f\"Initialized Medusa with {medusa_num_heads} heads\")\n",
    "\n",
    "        # Calculate baseline speed for later comparison\n",
    "        self._baseline_tokens_per_second = self._calculate_baseline_speed()\n",
    "\n",
    "    def _initialize_medusa_buffers(self) -> Dict:\n",
    "        \"\"\"Initialize Medusa buffers for speculative decoding.\"\"\"\n",
    "        # Create buffers similar to how the Medusa model does it\n",
    "        tree_indices = torch.zeros((self.medusa_num_heads, 2), dtype=torch.long)\n",
    "        medusa_attn_mask = torch.ones((self.medusa_num_heads + 1, self.medusa_num_heads + 1), dtype=torch.bool)\n",
    "        medusa_attn_mask = torch.triu(medusa_attn_mask, diagonal=1)\n",
    "        medusa_position_ids = torch.arange(self.medusa_num_heads, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"tree_indices\": tree_indices,\n",
    "            \"medusa_attn_mask\": medusa_attn_mask,\n",
    "            \"medusa_position_ids\": medusa_position_ids,\n",
    "            \"retrieve_indices\": None  # Will be set during generation\n",
    "        }\n",
    "\n",
    "    def _calculate_baseline_speed(self) -> float:\n",
    "        \"\"\"Calculate baseline generation speed without Medusa.\"\"\"\n",
    "        prompt = \"Once upon a time\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = self.llama_model(prompt, max_tokens=20, temperature=0.7)\n",
    "\n",
    "        if response and 'choices' in response:\n",
    "            generated_text = response['choices'][0]['text']\n",
    "            tokens = len(generated_text.split())\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            if elapsed_time > 0 and tokens > 0:\n",
    "                tokens_per_second = tokens / elapsed_time\n",
    "                self.logger.info(f\"Baseline generation speed: {tokens_per_second:.2f} tokens/second\")\n",
    "                return tokens_per_second\n",
    "\n",
    "        # Default value if calculation fails\n",
    "        return 5.0\n",
    "\n",
    "    # def generate(\n",
    "    #     self,\n",
    "    #     prompt: str,\n",
    "    #     max_length: int = 512,\n",
    "    #     temperature: float = 0.7,\n",
    "    #     posterior_threshold: float = 0.09,\n",
    "    #     posterior_alpha: float = 0.3\n",
    "    # ) -> Dict:\n",
    "    #     \"\"\"Generate text using Medusa speculative decoding with llama.cpp backend.\"\"\"\n",
    "    #     with self.model_lock:  # Ensure thread safety\n",
    "    #         start_time = time.time()\n",
    "\n",
    "    #         input_text = prompt\n",
    "    #         generated_text = \"\"\n",
    "    #         tokens_generated = 0\n",
    "    #         draft_tokens_generated = 0\n",
    "    #         accepted_tokens = 0\n",
    "\n",
    "    #         # Add a safeguard counter to prevent infinite loops\n",
    "    #         iteration = 0\n",
    "    #         max_iterations = max_length * 2\n",
    "\n",
    "    #         while tokens_generated < max_length and iteration < max_iterations:\n",
    "    #             iteration += 1\n",
    "    #             # Generate base prediction and drafts\n",
    "    #             base_token, drafts = self._generate_drafts(input_text, temperature)\n",
    "\n",
    "    #             if not base_token:\n",
    "    #                 self.logger.info(\"No base token generated, breaking loop.\")\n",
    "    #                 break\n",
    "\n",
    "    #             # Verify the draft tokens\n",
    "    #             accepted_count, accepted_drafts = self._verify_drafts(\n",
    "    #                 input_text,\n",
    "    #                 [base_token] + drafts,\n",
    "    #                 temperature,\n",
    "    #                 posterior_threshold,\n",
    "    #                 posterior_alpha\n",
    "    #             )\n",
    "\n",
    "    #             draft_tokens_generated += len(drafts) + 1  # base + drafts\n",
    "    #             accepted_tokens += accepted_count\n",
    "\n",
    "    #             # Append accepted tokens; if none are accepted, append base token\n",
    "    #             if accepted_count > 0:\n",
    "    #                 accepted_text = ''.join(accepted_drafts)\n",
    "    #                 input_text += accepted_text\n",
    "    #                 generated_text += accepted_text\n",
    "    #                 tokens_generated += accepted_count\n",
    "    #             else:\n",
    "    #                 input_text += base_token\n",
    "    #                 generated_text += base_token\n",
    "    #                 tokens_generated += 1\n",
    "\n",
    "    #             if tokens_generated % 50 == 0:\n",
    "    #                 self.logger.info(f\"Generated {tokens_generated} tokens so far.\")\n",
    "\n",
    "    #         elapsed_time = time.time() - start_time\n",
    "    #         tokens_per_second = tokens_generated / elapsed_time if elapsed_time > 0 else 0\n",
    "    #         speedup = tokens_per_second / self._baseline_tokens_per_second\n",
    "\n",
    "    #         return {\n",
    "    #             \"text\": generated_text,\n",
    "    #             \"generation_time\": elapsed_time,\n",
    "    #             \"tokens_generated\": tokens_generated,\n",
    "    #             \"tokens_per_second\": tokens_per_second,\n",
    "    #             \"speedup_factor\": speedup,\n",
    "    #             \"acceptance_rate\": (accepted_tokens / draft_tokens_generated * 100) if draft_tokens_generated > 0 else 0\n",
    "    #         }\n",
    "    def generate(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        max_length: int = 512,\n",
    "        temperature: float = 0.7,\n",
    "        posterior_threshold: float = 0.09,\n",
    "        posterior_alpha: float = 0.3\n",
    "    ) -> Dict:\n",
    "        \"\"\"Generate text using Medusa speculative decoding with llama.cpp backend.\"\"\"\n",
    "        with self.model_lock:  # Ensure thread safety\n",
    "            start_time = time.time()\n",
    "\n",
    "            input_text = prompt\n",
    "            generated_text = \"\"\n",
    "            tokens_generated = 0\n",
    "            draft_tokens_generated = 0\n",
    "            accepted_tokens = 0\n",
    "\n",
    "            # Add a safeguard counter and reduce max iterations for faster completion\n",
    "            iteration = 0\n",
    "            max_iterations = min(max_length * 2, 200)  # Cap iterations for reliability\n",
    "            batch_size = 5  # Generate this many tokens per batch for better efficiency\n",
    "\n",
    "            while tokens_generated < max_length and iteration < max_iterations:\n",
    "                iteration += 1\n",
    "\n",
    "                # Standard generation for first token (more reliable)\n",
    "                if tokens_generated == 0:\n",
    "                    try:\n",
    "                        response = self.llama_model(\n",
    "                            input_text,\n",
    "                            max_tokens=batch_size,  # Generate several tokens at once\n",
    "                            temperature=temperature,\n",
    "                            echo=False\n",
    "                        )\n",
    "                        if response and 'choices' in response:\n",
    "                            new_text = response['choices'][0]['text']\n",
    "                            if new_text:\n",
    "                                input_text += new_text\n",
    "                                generated_text += new_text\n",
    "                                tokens_generated += len(new_text.split())\n",
    "                        else:\n",
    "                            break\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        self.logger.error(f\"Error in initial generation: {str(e)}\")\n",
    "                        break\n",
    "\n",
    "                # For subsequent tokens, use Medusa speculative decoding\n",
    "                base_token, drafts = self._generate_drafts(input_text, temperature)\n",
    "\n",
    "                if not base_token:\n",
    "                    self.logger.info(\"No base token generated, breaking loop.\")\n",
    "                    break\n",
    "\n",
    "                # Verify the draft tokens\n",
    "                accepted_count, accepted_drafts = self._verify_drafts(\n",
    "                    input_text,\n",
    "                    [base_token] + drafts,\n",
    "                    temperature,\n",
    "                    posterior_threshold,\n",
    "                    posterior_alpha\n",
    "                )\n",
    "\n",
    "                draft_tokens_generated += len(drafts) + 1  # base + drafts\n",
    "                accepted_tokens += accepted_count\n",
    "\n",
    "                # Append accepted tokens; if none are accepted, append base token\n",
    "                if accepted_count > 0:\n",
    "                    accepted_text = ''.join(accepted_drafts)\n",
    "                    input_text += accepted_text\n",
    "                    generated_text += accepted_text\n",
    "                    tokens_generated += accepted_count\n",
    "                else:\n",
    "                    input_text += base_token\n",
    "                    generated_text += base_token\n",
    "                    tokens_generated += 1\n",
    "\n",
    "                if tokens_generated % 20 == 0:\n",
    "                    self.logger.info(f\"Generated {tokens_generated} tokens so far.\")\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            tokens_per_second = tokens_generated / elapsed_time if elapsed_time > 0 else 0\n",
    "            speedup = tokens_per_second / self._baseline_tokens_per_second\n",
    "\n",
    "            return {\n",
    "                \"text\": generated_text,\n",
    "                \"generation_time\": elapsed_time,\n",
    "                \"tokens_generated\": tokens_generated,\n",
    "                \"tokens_per_second\": tokens_per_second,\n",
    "                \"speedup_factor\": speedup,\n",
    "                \"acceptance_rate\": (accepted_tokens / draft_tokens_generated * 100) if draft_tokens_generated > 0 else 0\n",
    "            }\n",
    "\n",
    "    def _generate_drafts(self, context: str, temperature: float):\n",
    "        \"\"\"Generate a base token and draft tokens using Medusa tree structure.\"\"\"\n",
    "        try:\n",
    "            # Generate the base token\n",
    "            base_response = self.llama_model(\n",
    "                context,\n",
    "                max_tokens=1,\n",
    "                temperature=temperature,\n",
    "                echo=False\n",
    "            )\n",
    "\n",
    "            if not base_response or 'choices' not in base_response:\n",
    "                return \"\", []\n",
    "\n",
    "            base_token = base_response['choices'][0]['text']\n",
    "\n",
    "            # Generate draft tokens\n",
    "            drafts = []\n",
    "            draft_context = context + base_token\n",
    "\n",
    "            for _ in range(self.medusa_num_heads - 1):  # Exclude base token already generated\n",
    "                draft_response = self.llama_model(\n",
    "                    draft_context,\n",
    "                    max_tokens=1,\n",
    "                    temperature=temperature,\n",
    "                    echo=False\n",
    "                )\n",
    "\n",
    "                if draft_response and 'choices' in draft_response:\n",
    "                    draft_token = draft_response['choices'][0]['text']\n",
    "                    drafts.append(draft_token)\n",
    "                    draft_context += draft_token\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            return base_token, drafts\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error generating drafts: {str(e)}\")\n",
    "            return \"\", []\n",
    "\n",
    "    # def _verify_drafts(\n",
    "    #     self,\n",
    "    #     context: str,\n",
    "    #     drafts: List[str],\n",
    "    #     temperature: float,\n",
    "    #     threshold: float,\n",
    "    #     alpha: float\n",
    "    # ):\n",
    "    #     \"\"\"Verify draft tokens and return accepted tokens.\"\"\"\n",
    "    #     if not drafts:\n",
    "    #         return 0, []\n",
    "\n",
    "    #     scores = []\n",
    "    #     accepted_drafts = []\n",
    "    #     current_context = context\n",
    "\n",
    "    #     for draft in drafts:\n",
    "    #         try:\n",
    "    #             verify_response = self.llama_model(\n",
    "    #                 current_context + draft,\n",
    "    #                 max_tokens=0,\n",
    "    #                 temperature=0.0,  # Set temperature to zero for deterministic output\n",
    "    #                 echo=True\n",
    "    #             )\n",
    "\n",
    "    #             score = 0.0\n",
    "    #             if verify_response and 'choices' in verify_response:\n",
    "    #                 score = float(verify_response['choices'][0].get('logprobs', {}).get('token_logprobs', [-1.0])[-1])\n",
    "\n",
    "    #             score = np.exp(score / max(temperature, 1e-6)) ** alpha\n",
    "    #             scores.append(score)\n",
    "\n",
    "    #             # Accept draft if score exceeds the threshold\n",
    "    #             if score >= threshold:\n",
    "    #                 accepted_drafts.append(draft)\n",
    "    #                 current_context += draft\n",
    "    #             else:\n",
    "    #                 break\n",
    "\n",
    "    #         except Exception as e:\n",
    "    #             self.logger.error(f\"Error verifying draft: {str(e)}\")\n",
    "    #             break\n",
    "\n",
    "    #     return len(accepted_drafts), accepted_drafts\n",
    "    def _verify_drafts(\n",
    "        self,\n",
    "        context: str,\n",
    "        drafts: List[str],\n",
    "        temperature: float,\n",
    "        threshold: float,\n",
    "        alpha: float\n",
    "    ):\n",
    "        \"\"\"Verify draft tokens and return accepted tokens.\"\"\"\n",
    "        if not drafts:\n",
    "            return 0, []\n",
    "\n",
    "        scores = []\n",
    "        accepted_drafts = []\n",
    "        current_context = context\n",
    "\n",
    "        for draft in drafts:\n",
    "            try:\n",
    "                verify_response = self.llama_model(\n",
    "                    current_context + draft,\n",
    "                    max_tokens=0,\n",
    "                    temperature=0.0,  # Set temperature to zero for deterministic output\n",
    "                    echo=True\n",
    "                )\n",
    "\n",
    "                # Simplified scoring - more robust against missing attributes\n",
    "                score = 0.0\n",
    "                if verify_response and 'choices' in verify_response:\n",
    "                    choice = verify_response['choices'][0]\n",
    "                    # Try different methods to get a score\n",
    "                    if 'logprobs' in choice and choice['logprobs']:\n",
    "                        token_logprobs = choice['logprobs'].get('token_logprobs', [])\n",
    "                        if token_logprobs:\n",
    "                            score = float(token_logprobs[-1])\n",
    "                    elif 'score' in choice:\n",
    "                        score = float(choice['score'])\n",
    "                    # Fallback scoring method if logprobs not available\n",
    "                    else:\n",
    "                        # Simple heuristic: check if model output matches our draft\n",
    "                        model_output = choice.get('text', '')\n",
    "                        if model_output.endswith(draft):\n",
    "                            score = 0.0  # Good score\n",
    "                        else:\n",
    "                            score = -5.0  # Bad score\n",
    "\n",
    "                # Apply temperature and alpha\n",
    "                adjusted_score = np.exp(score / max(temperature, 1e-6)) ** alpha\n",
    "                scores.append(adjusted_score)\n",
    "\n",
    "                # Accept draft if score exceeds the threshold\n",
    "                if adjusted_score >= threshold:\n",
    "                    accepted_drafts.append(draft)\n",
    "                    current_context += draft\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error verifying draft: {str(e)}\")\n",
    "                break\n",
    "\n",
    "        return len(accepted_drafts), accepted_drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:13:28.378320Z",
     "iopub.status.busy": "2025-03-28T10:13:28.377930Z",
     "iopub.status.idle": "2025-03-28T10:13:28.388871Z",
     "shell.execute_reply": "2025-03-28T10:13:28.387827Z",
     "shell.execute_reply.started": "2025-03-28T10:13:28.378285Z"
    },
    "id": "O6ns_X7wBsYL"
   },
   "outputs": [],
   "source": [
    "class BatchProcessor:\n",
    "    \"\"\"Processes generation requests in batches for better efficiency.\"\"\"\n",
    "    def __init__(self, model_manager, batch_size=4, max_wait_time=0.1):\n",
    "        self.model_manager = model_manager\n",
    "        self.batch_size = batch_size\n",
    "        self.max_wait_time = max_wait_time\n",
    "        self.queue = asyncio.Queue()\n",
    "        self.logger = logging.getLogger(\"BatchProcessor\")\n",
    "        self.processing = False\n",
    "        self.results = {}\n",
    "        self.background_task = None\n",
    "\n",
    "    async def add_request(self, request: BatchRequest) -> str:\n",
    "        \"\"\"Add a generation request to the queue.\"\"\"\n",
    "        await self.queue.put(request)\n",
    "        self.logger.info(f\"Added request {request.id} to queue, current size: {self.queue.qsize()}\")\n",
    "\n",
    "        # Start processing if not already running\n",
    "        if not self.processing:\n",
    "            self.processing = True\n",
    "            self.background_task = asyncio.create_task(self._process_queue())\n",
    "\n",
    "        return request.id\n",
    "\n",
    "    async def get_result(self, request_id: str, timeout: float = 180.0) -> Optional[Dict]:\n",
    "        \"\"\"Wait for and retrieve result for a specific request ID.\"\"\"\n",
    "        start_time = time.time()\n",
    "        while time.time() - start_time < timeout:\n",
    "            if request_id in self.results:\n",
    "                result = self.results.pop(request_id)\n",
    "                return result\n",
    "            await asyncio.sleep(0.1)\n",
    "        return None  # Timed out\n",
    "\n",
    "    # async def _process_queue(self):\n",
    "    #     \"\"\"Background task to process requests in batches.\"\"\"\n",
    "    #     try:\n",
    "    #         while True:\n",
    "    #             batch = []\n",
    "    #             # Try to collect up to batch_size requests\n",
    "    #             for _ in range(self.batch_size):\n",
    "    #                 try:\n",
    "    #                     request = await asyncio.wait_for(\n",
    "    #                         self.queue.get(),\n",
    "    #                         timeout=self.max_wait_time\n",
    "    #                     )\n",
    "    #                     batch.append(request)\n",
    "    #                 except asyncio.TimeoutError:\n",
    "    #                     break\n",
    "\n",
    "    #             if not batch:\n",
    "    #                 self.processing = False\n",
    "    #                 break\n",
    "\n",
    "    #             self.logger.info(f\"Processing batch of {len(batch)} requests\")\n",
    "\n",
    "    #             # Process each request in the batch off the main event loop\n",
    "    #             for request in batch:\n",
    "    #                 try:\n",
    "    #                     # Offload the generation call to a separate thread so as not to block\n",
    "    #                     result = await asyncio.to_thread(\n",
    "    #                         self.model_manager.generate,\n",
    "    #                         prompt=request.prompt,\n",
    "    #                         max_length=request.max_length,\n",
    "    #                         temperature=request.temperature,\n",
    "    #                         posterior_threshold=request.posterior_threshold,\n",
    "    #                         posterior_alpha=request.posterior_alpha\n",
    "    #                     )\n",
    "    #                     self.results[request.id] = result\n",
    "    #                     self.logger.info(f\"Completed request {request.id}\")\n",
    "    #                 except Exception as e:\n",
    "    #                     self.logger.error(f\"Error processing request {request.id}: {str(e)}\")\n",
    "    #                     self.results[request.id] = {\"error\": str(e)}\n",
    "    #                 finally:\n",
    "    #                     self.queue.task_done()\n",
    "    #     except Exception as e:\n",
    "    #         self.logger.error(f\"Error in batch processing: {str(e)}\")\n",
    "    #         self.processing = False\n",
    "\n",
    "    async def _process_queue(self):\n",
    "        \"\"\"Background task to process requests in batches.\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                batch = []\n",
    "                # Try to collect up to batch_size requests\n",
    "                for _ in range(self.batch_size):\n",
    "                    try:\n",
    "                        request = await asyncio.wait_for(\n",
    "                            self.queue.get(),\n",
    "                            timeout=self.max_wait_time\n",
    "                        )\n",
    "                        batch.append(request)\n",
    "                    except asyncio.TimeoutError:\n",
    "                        break\n",
    "\n",
    "                if not batch:\n",
    "                    self.processing = False\n",
    "                    break\n",
    "\n",
    "                self.logger.info(f\"Processing batch of {len(batch)} requests\")\n",
    "\n",
    "                # Process each request in parallel (create tasks)\n",
    "                processing_tasks = []\n",
    "                for request in batch:\n",
    "                    task = asyncio.create_task(self._process_single_request(request))\n",
    "                    processing_tasks.append(task)\n",
    "\n",
    "                # Wait for all processing to complete\n",
    "                await asyncio.gather(*processing_tasks)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in batch processing: {str(e)}\")\n",
    "            self.processing = False\n",
    "\n",
    "    async def _process_single_request(self, request: BatchRequest):\n",
    "        \"\"\"Process a single request in the batch.\"\"\"\n",
    "        try:\n",
    "            # Offload the generation call to a thread pool\n",
    "            result = await asyncio.to_thread(\n",
    "                self.model_manager.generate,\n",
    "                prompt=request.prompt,\n",
    "                max_length=request.max_length,\n",
    "                temperature=request.temperature,\n",
    "                posterior_threshold=request.posterior_threshold,\n",
    "                posterior_alpha=request.posterior_alpha\n",
    "            )\n",
    "            self.results[request.id] = result\n",
    "            self.logger.info(f\"Completed request {request.id}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing request {request.id}: {str(e)}\")\n",
    "            self.results[request.id] = {\"error\": str(e)}\n",
    "        finally:\n",
    "            self.queue.task_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dVp8NbLxCzpI",
    "outputId": "53a17db3-2622-4406-97b7-ba45722f5aee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      16.59 ms /   279 runs   (    0.06 ms per token, 16813.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  154073.68 ms /   279 runs   (  552.24 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =  154424.48 ms /   279 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global variables for model manager and batch processor\n",
    "model_manager = None\n",
    "batch_processor = None\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Lifespan context for startup and shutdown actions.\"\"\"\n",
    "    global model_manager, batch_processor\n",
    "\n",
    "    logger.info(\"Initializing model and batch processor...\")\n",
    "    try:\n",
    "        model_manager = MedusaLlamaCppManager(\n",
    "            model_path=\"/kaggle/input/vicuna-1/gguf/default/1/vicuna-7b-v1.3-F16_KM.gguf\",\n",
    "            medusa_num_heads=4\n",
    "        )\n",
    "        batch_processor = BatchProcessor(model_manager)\n",
    "        logger.info(\"Model and batch processor initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Set up ngrok tunnel for external access\n",
    "        ngrok_tunnel = ngrok.connect(8000)\n",
    "        logger.info(f\"Ngrok tunnel established at: {ngrok_tunnel.public_url}\")\n",
    "        print(f\"Public URL: {ngrok_tunnel.public_url}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to establish ngrok tunnel: {str(e)}\")\n",
    "\n",
    "    yield\n",
    "\n",
    "    # Shutdown procedures can be added here\n",
    "    logger.info(\"Shutting down server and cleaning up resources.\")\n",
    "\n",
    "# Initialize FastAPI app with lifespan context\n",
    "app = FastAPI(\n",
    "    title=\"Medusa LLM Service\",\n",
    "    description=\"Language model service with Medusa speculative decoding and dynamic batching\",\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "# Endpoint for text generation\n",
    "@app.post(\"/generate\", response_model=GenerationResponse)\n",
    "async def generate_text(request: GenerationRequest):\n",
    "    try:\n",
    "        # Create a batch request with a unique id\n",
    "        request_id = str(uuid.uuid4())\n",
    "        batch_request = BatchRequest(\n",
    "            id=request_id,\n",
    "            prompt=request.prompt,\n",
    "            timestamp=datetime.now(),\n",
    "            max_length=min(request.max_length, 200),\n",
    "            temperature=request.temperature,\n",
    "            posterior_threshold=request.posterior_threshold,\n",
    "            posterior_alpha=request.posterior_alpha\n",
    "        )\n",
    "\n",
    "        # Add the request to the batch processor\n",
    "        await batch_processor.add_request(batch_request)\n",
    "\n",
    "        # Wait for the result; if it times out, return an error\n",
    "        result = await batch_processor.get_result(request_id, timeout=300.0)\n",
    "        if not result:\n",
    "            raise HTTPException(status_code=408, detail=\"Request timed out after 5 minutes\")\n",
    "        if \"error\" in result:\n",
    "            raise HTTPException(status_code=500, detail=result[\"error\"])\n",
    "\n",
    "        return GenerationResponse(\n",
    "            text=result[\"text\"],\n",
    "            generation_time=result[\"generation_time\"],\n",
    "            tokens_generated=result[\"tokens_generated\"],\n",
    "            tokens_per_second=result[\"tokens_per_second\"],\n",
    "            speedup_factor=result[\"speedup_factor\"]\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in generate endpoint: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Health check endpoint\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    return {\"status\": \"healthy\", \"model\": \"Medusa LLM Service\"}\n",
    "\n",
    "# Benchmark endpoint to compare Medusa decoding with standard generation\n",
    "@app.post(\"/benchmark\")\n",
    "async def benchmark(request: GenerationRequest):\n",
    "    try:\n",
    "        # Offload Medusa generation to a thread to prevent blocking\n",
    "        medusa_result = await asyncio.to_thread(\n",
    "            model_manager.generate,\n",
    "            prompt=request.prompt,\n",
    "            max_length=request.max_length,\n",
    "            temperature=request.temperature,\n",
    "            posterior_threshold=request.posterior_threshold,\n",
    "            posterior_alpha=request.posterior_alpha\n",
    "        )\n",
    "\n",
    "        # Standard generation call (also offloaded to a thread)\n",
    "        start_time = time.time()\n",
    "        standard_response = await asyncio.to_thread(\n",
    "            model_manager.llama_model,\n",
    "            request.prompt,\n",
    "            max_tokens=request.max_length,\n",
    "            temperature=request.temperature\n",
    "        )\n",
    "        standard_time = time.time() - start_time\n",
    "\n",
    "        standard_text = standard_response['choices'][0]['text'] if standard_response and 'choices' in standard_response else \"\"\n",
    "        standard_tokens = len(standard_text.split())\n",
    "        standard_tokens_per_second = standard_tokens / standard_time if standard_time > 0 else 0\n",
    "\n",
    "        return {\n",
    "            \"medusa\": {\n",
    "                \"text\": medusa_result[\"text\"],\n",
    "                \"generation_time\": medusa_result[\"generation_time\"],\n",
    "                \"tokens_generated\": medusa_result[\"tokens_generated\"],\n",
    "                \"tokens_per_second\": medusa_result[\"tokens_per_second\"],\n",
    "                \"acceptance_rate\": medusa_result[\"acceptance_rate\"]\n",
    "            },\n",
    "            \"standard\": {\n",
    "                \"text\": standard_text,\n",
    "                \"generation_time\": standard_time,\n",
    "                \"tokens_generated\": standard_tokens,\n",
    "                \"tokens_per_second\": standard_tokens_per_second\n",
    "            },\n",
    "            \"speedup\": medusa_result[\"tokens_per_second\"] / standard_tokens_per_second if standard_tokens_per_second > 0 else 0\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in benchmark endpoint: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Function to start the server; works for both notebook and standard Python environments\n",
    "async def start_server():\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "# Entry point for running the file directly\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    try:\n",
    "        # Check if running in a notebook environment (e.g., Colab or Jupyter)\n",
    "        if 'google.colab' in str(get_ipython()):\n",
    "            asyncio.run(start_server())\n",
    "        else:\n",
    "            uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "    except NameError:\n",
    "        # If get_ipython() is not defined, assume standard Python environment\n",
    "        uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKtRiC2A-gX9"
   },
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T10:37:32.439541Z",
     "iopub.status.busy": "2025-03-28T10:37:32.438992Z",
     "iopub.status.idle": "2025-03-28T11:11:03.302690Z",
     "shell.execute_reply": "2025-03-28T11:11:03.301781Z",
     "shell.execute_reply.started": "2025-03-28T10:37:32.439492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1398]\n",
      "INFO:     Waiting for application startup.\n",
      "llama_model_loader: loaded meta data with 26 key-value pairs and 291 tensors from /kaggle/input/vicuna-1/gguf/default/1/vicuna-7b-v1.3-F16_KM.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Vicuna 7b v1.3\n",
      "llama_model_loader: - kv   3:                            general.version str              = v1.3\n",
      "llama_model_loader: - kv   4:                           general.basename str              = vicuna\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 7B\n",
      "llama_model_loader: - kv   6:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   7:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv   8:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   9:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv  10:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  12:                           llama.vocab_size u32              = 32000\n",
      "llama_model_loader: - kv  13:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  15:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  25:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 3\n",
      "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = Vicuna 7b v1.3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.file_type': '15', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.eos_token_id': '2', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.architecture': 'llama', 'llama.block_count': '32', 'tokenizer.ggml.padding_token_id': '0', 'general.basename': 'vicuna', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'default', 'llama.context_length': '2048', 'general.name': 'Vicuna 7b v1.3', 'llama.rope.dimension_count': '128', 'general.version': 'v1.3', 'general.type': 'model', 'general.size_label': '7B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.vocab_size': '32000'}\n",
      "Using fallback chat format: llama-2\n",
      "\n",
      "llama_print_timings:        load time =    1994.11 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /    20 runs   (    0.08 ms per token, 13114.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1994.04 ms /     5 tokens (  398.81 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:        eval time =   14598.58 ms /    19 runs   (  768.35 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =   16613.51 ms /    24 tokens\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://e7c0-35-194-149-242.ngrok-free.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      16.93 ms /   278 runs   (    0.06 ms per token, 16417.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  159251.55 ms /   278 runs   (  572.85 ms per token,     1.75 tokens per second)\n",
      "llama_print_timings:       total time =  159611.16 ms /   278 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      40.61 ms /   687 runs   (    0.06 ms per token, 16917.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  403647.72 ms /   687 runs   (  587.55 ms per token,     1.70 tokens per second)\n",
      "llama_print_timings:       total time =  404989.57 ms /   687 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1994.11 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /   100 runs   (    0.07 ms per token, 13640.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.57 ms /     4 tokens (  413.89 ms per token,     2.42 tokens per second)\n",
      "llama_print_timings:        eval time =   74541.80 ms /    99 runs   (  752.95 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =   76302.58 ms /   103 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     14.102.161.98:0 - \"POST /generate HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      17.51 ms /   277 runs   (    0.06 ms per token, 15822.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  173918.87 ms /   277 runs   (  627.87 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:       total time =  174276.21 ms /   277 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      16.50 ms /   276 runs   (    0.06 ms per token, 16729.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  151989.96 ms /   276 runs   (  550.69 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =  152353.18 ms /   276 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     509.03 ms /     1 runs   (  509.03 ms per token,     1.96 tokens per second)\n",
      "llama_print_timings:       total time =     510.14 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     533.80 ms /     1 runs   (  533.80 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =     535.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10869.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     537.76 ms /     1 runs   (  537.76 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =     538.53 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     564.03 ms /     1 runs   (  564.03 ms per token,     1.77 tokens per second)\n",
      "llama_print_timings:       total time =     564.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      16.67 ms /   275 runs   (    0.06 ms per token, 16496.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  151203.99 ms /   275 runs   (  549.83 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =  151555.84 ms /   275 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      41.59 ms /   686 runs   (    0.06 ms per token, 16495.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  403541.96 ms /   686 runs   (  588.25 ms per token,     1.70 tokens per second)\n",
      "llama_print_timings:       total time =  404902.56 ms /   686 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1994.11 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /   100 runs   (    0.07 ms per token, 14293.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3033.14 ms /     8 tokens (  379.14 ms per token,     2.64 tokens per second)\n",
      "llama_print_timings:        eval time =   75183.18 ms /    99 runs   (  759.43 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =   78319.96 ms /   107 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     14.102.161.98:0 - \"POST /generate HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      17.04 ms /   274 runs   (    0.06 ms per token, 16078.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  171410.01 ms /   274 runs   (  625.58 ms per token,     1.60 tokens per second)\n",
      "llama_print_timings:       total time =  171746.36 ms /   274 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      16.41 ms /   273 runs   (    0.06 ms per token, 16631.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  150110.21 ms /   273 runs   (  549.85 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =  150455.15 ms /   273 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      39.31 ms /   685 runs   (    0.06 ms per token, 17425.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  410239.87 ms /   685 runs   (  598.89 ms per token,     1.67 tokens per second)\n",
      "llama_print_timings:       total time =  411527.70 ms /   685 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10101.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     528.08 ms /     1 runs   (  528.08 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     528.97 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     551.36 ms /     1 runs   (  551.36 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =     552.18 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     537.12 ms /     1 runs   (  537.12 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =     537.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     518.49 ms /     1 runs   (  518.49 ms per token,     1.93 tokens per second)\n",
      "llama_print_timings:       total time =     518.96 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      17.15 ms /   272 runs   (    0.06 ms per token, 15863.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  150949.10 ms /   272 runs   (  554.96 ms per token,     1.80 tokens per second)\n",
      "llama_print_timings:       total time =  151286.42 ms /   272 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     543.60 ms /     1 runs   (  543.60 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =     543.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     505.85 ms /     1 runs   (  505.85 ms per token,     1.98 tokens per second)\n",
      "llama_print_timings:       total time =     508.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     519.23 ms /     1 runs   (  519.23 ms per token,     1.93 tokens per second)\n",
      "llama_print_timings:       total time =     523.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     498.41 ms /     1 runs   (  498.41 ms per token,     2.01 tokens per second)\n",
      "llama_print_timings:       total time =     498.73 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      16.68 ms /   271 runs   (    0.06 ms per token, 16248.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  150525.99 ms /   271 runs   (  555.45 ms per token,     1.80 tokens per second)\n",
      "llama_print_timings:       total time =  150886.49 ms /   271 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      16.45 ms /   270 runs   (    0.06 ms per token, 16413.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  165911.07 ms /   270 runs   (  614.49 ms per token,     1.63 tokens per second)\n",
      "llama_print_timings:       total time =  166258.00 ms /   270 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1994.11 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /   100 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   77550.41 ms /   100 runs   (  775.50 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =   77659.11 ms /   100 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     14.102.161.98:0 - \"POST /generate HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      40.55 ms /   684 runs   (    0.06 ms per token, 16868.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  415184.34 ms /   684 runs   (  606.99 ms per token,     1.65 tokens per second)\n",
      "llama_print_timings:       total time =  416567.46 ms /   684 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      17.78 ms /   269 runs   (    0.07 ms per token, 15130.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  161112.95 ms /   269 runs   (  598.93 ms per token,     1.67 tokens per second)\n",
      "llama_print_timings:       total time =  161463.67 ms /   269 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      17.89 ms /   268 runs   (    0.07 ms per token, 14981.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  150808.59 ms /   268 runs   (  562.72 ms per token,     1.78 tokens per second)\n",
      "llama_print_timings:       total time =  151140.26 ms /   268 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     529.14 ms /     1 runs   (  529.14 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     529.77 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     529.41 ms /     1 runs   (  529.41 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     532.07 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     549.76 ms /     1 runs   (  549.76 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =     550.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 23255.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     541.82 ms /     1 runs   (  541.82 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =     542.32 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      42.59 ms /   683 runs   (    0.06 ms per token, 16037.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  396931.10 ms /   683 runs   (  581.16 ms per token,     1.72 tokens per second)\n",
      "llama_print_timings:       total time =  398281.41 ms /   683 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      17.98 ms /   267 runs   (    0.07 ms per token, 14845.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  151400.91 ms /   267 runs   (  567.04 ms per token,     1.76 tokens per second)\n",
      "llama_print_timings:       total time =  151745.81 ms /   267 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [1398]\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      15.88 ms /   266 runs   (    0.06 ms per token, 16750.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  150186.75 ms /   266 runs   (  564.61 ms per token,     1.77 tokens per second)\n",
      "llama_print_timings:       total time =  150542.81 ms /   266 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import logging\n",
    "import asyncio\n",
    "from typing import List, Dict, Optional\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from pyngrok import ngrok\n",
    "import time\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from threading import Lock\n",
    "from contextlib import asynccontextmanager\n",
    "import uvicorn\n",
    "import os\n",
    "\n",
    "# For notebook environments\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Import Medusa components from the repository\n",
    "from medusa.model.medusa_model import MedusaModel\n",
    "from medusa.model.medusa_choices import mc_sim_7b_63\n",
    "from medusa.model.utils import generate_medusa_buffers\n",
    "from medusa.model.kv_cache import initialize_past_key_values\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define request and response models\n",
    "class GenerationRequest(BaseModel):\n",
    "    prompt: str\n",
    "    max_length: int = 512\n",
    "    temperature: float = 0.7\n",
    "    posterior_threshold: float = 0.09\n",
    "    posterior_alpha: float = 0.3\n",
    "\n",
    "class GenerationResponse(BaseModel):\n",
    "    text: str\n",
    "    generation_time: float\n",
    "    tokens_generated: int\n",
    "    tokens_per_second: float\n",
    "    speedup_factor: Optional[float] = None\n",
    "\n",
    "class MedusaLlamaCppManager:\n",
    "    \"\"\"\n",
    "    Manager class that combines llama.cpp with Medusa for speculative decoding.\n",
    "    This class loads the model, sets up Medusa buffers, and provides text generation.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str,\n",
    "        medusa_num_heads: int = 4,\n",
    "        n_ctx: int = 2048,\n",
    "        n_batch: int = 512,\n",
    "        n_threads: int = 8\n",
    "    ):\n",
    "        self.logger = logging.getLogger(\"MedusaLlamaCppManager\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.medusa_num_heads = medusa_num_heads\n",
    "        self.model_lock = Lock()  # For thread safety\n",
    "\n",
    "        # Check if model exists\n",
    "        if not os.path.exists(model_path):\n",
    "            self.logger.error(f\"Model file not found at {model_path}\")\n",
    "            raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "        # Load compiled model using llama.cpp backend\n",
    "        self.logger.info(f\"Loading model from {model_path}...\")\n",
    "        self.llama_model = Llama(\n",
    "            model_path=model_path,\n",
    "            n_ctx=n_ctx,\n",
    "            n_batch=n_batch,\n",
    "            n_threads=n_threads,\n",
    "            n_gpu_layers=-1,  # Use all GPU layers\n",
    "            verbose=True  # For debugging\n",
    "        )\n",
    "        self.logger.info(f\"Loaded GGUF model from {model_path}\")\n",
    "\n",
    "        # Calculate baseline speed for later comparison\n",
    "        self._baseline_tokens_per_second = self._calculate_baseline_speed()\n",
    "        self.logger.info(f\"Baseline generation speed: {self._baseline_tokens_per_second:.2f} tokens/second\")\n",
    "\n",
    "    def _calculate_baseline_speed(self) -> float:\n",
    "        \"\"\"Calculate baseline generation speed without Medusa.\"\"\"\n",
    "        prompt = \"Once upon a time\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = self.llama_model(prompt, max_tokens=20, temperature=0.7)\n",
    "\n",
    "        if response and 'choices' in response:\n",
    "            generated_text = response['choices'][0]['text']\n",
    "            tokens = len(generated_text.split())\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            if elapsed_time > 0 and tokens > 0:\n",
    "                tokens_per_second = tokens / elapsed_time\n",
    "                self.logger.info(f\"Baseline generation speed: {tokens_per_second:.2f} tokens/second\")\n",
    "                return tokens_per_second\n",
    "\n",
    "        # Default value if calculation fails\n",
    "        return 5.0\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        max_length: int = 512,\n",
    "        temperature: float = 0.7,\n",
    "        posterior_threshold: float = 0.09,\n",
    "        posterior_alpha: float = 0.3\n",
    "    ) -> Dict:\n",
    "        \"\"\"Generate text using a simple, robust approach (no Medusa for reliability)\"\"\"\n",
    "        with self.model_lock:  # Ensure thread safety\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # For better reliability, use straightforward generation\n",
    "            self.logger.info(f\"Generating with prompt: {prompt[:50]}...\")\n",
    "            \n",
    "            try:\n",
    "                # Generate text using llama.cpp directly\n",
    "                response = self.llama_model(\n",
    "                    prompt,\n",
    "                    max_tokens=min(max_length, 100),  # Cap max tokens for reliability\n",
    "                    temperature=temperature,\n",
    "                    echo=False\n",
    "                )\n",
    "                \n",
    "                if not response or 'choices' not in response:\n",
    "                    self.logger.error(\"No response from model\")\n",
    "                    return {\n",
    "                        \"text\": \"Error: No response from model\",\n",
    "                        \"generation_time\": time.time() - start_time,\n",
    "                        \"tokens_generated\": 0,\n",
    "                        \"tokens_per_second\": 0,\n",
    "                        \"speedup_factor\": 0,\n",
    "                        \"acceptance_rate\": 0\n",
    "                    }\n",
    "                \n",
    "                generated_text = response['choices'][0]['text']\n",
    "                tokens_generated = len(generated_text.split())\n",
    "                \n",
    "                elapsed_time = time.time() - start_time\n",
    "                tokens_per_second = tokens_generated / elapsed_time if elapsed_time > 0 else 0\n",
    "                \n",
    "                self.logger.info(f\"Generated {tokens_generated} tokens in {elapsed_time:.2f} seconds\")\n",
    "                self.logger.info(f\"Generation speed: {tokens_per_second:.2f} tokens/second\")\n",
    "                \n",
    "                return {\n",
    "                    \"text\": generated_text,\n",
    "                    \"generation_time\": elapsed_time,\n",
    "                    \"tokens_generated\": tokens_generated,\n",
    "                    \"tokens_per_second\": tokens_per_second,\n",
    "                    \"speedup_factor\": tokens_per_second / self._baseline_tokens_per_second,\n",
    "                    \"acceptance_rate\": 0  # No speculative decoding in this approach\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in generation: {str(e)}\")\n",
    "                return {\n",
    "                    \"text\": f\"Error: {str(e)}\",\n",
    "                    \"generation_time\": time.time() - start_time,\n",
    "                    \"tokens_generated\": 0,\n",
    "                    \"tokens_per_second\": 0,\n",
    "                    \"speedup_factor\": 0,\n",
    "                    \"acceptance_rate\": 0\n",
    "                }\n",
    "\n",
    "# Global variables for model manager\n",
    "model_manager = None\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Lifespan context for startup and shutdown actions.\"\"\"\n",
    "    global model_manager\n",
    "\n",
    "    logger.info(\"Initializing model manager...\")\n",
    "    try:\n",
    "        model_path = \"/kaggle/input/vicuna-1/gguf/default/1/vicuna-7b-v1.3-F16_KM.gguf\"\n",
    "        model_manager = MedusaLlamaCppManager(\n",
    "            model_path=model_path,\n",
    "            medusa_num_heads=4,\n",
    "            n_ctx=2048,\n",
    "            n_batch=512,\n",
    "            n_threads=8\n",
    "        )\n",
    "        logger.info(\"Model manager initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Set up ngrok tunnel for external access\n",
    "        ngrok_tunnel = ngrok.connect(8000)\n",
    "        logger.info(f\"Ngrok tunnel established at: {ngrok_tunnel.public_url}\")\n",
    "        print(f\"Public URL: {ngrok_tunnel.public_url}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to establish ngrok tunnel: {str(e)}\")\n",
    "\n",
    "    yield\n",
    "\n",
    "    # Shutdown procedures can be added here\n",
    "    logger.info(\"Shutting down server and cleaning up resources.\")\n",
    "\n",
    "# Initialize FastAPI app with lifespan context\n",
    "app = FastAPI(\n",
    "    title=\"Medusa LLM Service\",\n",
    "    description=\"Simplified language model service\",\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "# Simple endpoint for text generation - no batch processing\n",
    "@app.post(\"/generate\", response_model=GenerationResponse)\n",
    "async def generate_text(request: GenerationRequest):\n",
    "    \"\"\"Process a single generation request directly\"\"\"\n",
    "    try:\n",
    "        if model_manager is None:\n",
    "            raise HTTPException(status_code=503, detail=\"Model not initialized\")\n",
    "        \n",
    "        logger.info(f\"Processing generation request with prompt: {request.prompt[:50]}...\")\n",
    "        \n",
    "        # Use asyncio.to_thread to avoid blocking the event loop\n",
    "        result = await asyncio.to_thread(\n",
    "            model_manager.generate,\n",
    "            prompt=request.prompt,\n",
    "            max_length=min(request.max_length, 100),  # Cap length for reliability\n",
    "            temperature=request.temperature,\n",
    "            posterior_threshold=request.posterior_threshold,\n",
    "            posterior_alpha=request.posterior_alpha\n",
    "        )\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            raise HTTPException(status_code=500, detail=result[\"error\"])\n",
    "            \n",
    "        return GenerationResponse(\n",
    "            text=result[\"text\"],\n",
    "            generation_time=result[\"generation_time\"],\n",
    "            tokens_generated=result[\"tokens_generated\"],\n",
    "            tokens_per_second=result[\"tokens_per_second\"],\n",
    "            speedup_factor=result[\"speedup_factor\"]\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in generate endpoint: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Health check endpoint\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Check if the service is healthy\"\"\"\n",
    "    # Also check if model is loaded\n",
    "    model_status = \"loaded\" if model_manager is not None else \"not loaded\"\n",
    "    return {\n",
    "        \"status\": \"healthy\", \n",
    "        \"model\": model_status,\n",
    "        \"device\": model_manager.device if model_manager else \"unknown\"\n",
    "    }\n",
    "\n",
    "# Function to start the server\n",
    "async def start_server():\n",
    "    \"\"\"Start the FastAPI server\"\"\"\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "# Entry point for running the file directly\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Check if running in a notebook environment\n",
    "        if 'google.colab' in globals() or 'kaggle_secrets' in globals():\n",
    "            # Running in notebook (Colab or Kaggle)\n",
    "            nest_asyncio.apply()\n",
    "            asyncio.run(start_server())\n",
    "        else:\n",
    "            # Standard Python environment\n",
    "            import uvicorn\n",
    "            uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error starting server: {str(e)}\")"
   ]
  },
  {
   "attachments": {
    "523e8c9b-a432-4d27-9419-dd9955a15ea8.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 1 only without medusa\n",
    "\n",
    "![image.png](attachment:523e8c9b-a432-4d27-9419-dd9955a15ea8.png)\n",
    "\n",
    "---\n",
    "\n",
    "### **Formatted cURL Request:**\n",
    "```bash\n",
    "curl -X POST \"https://e7c0-35-194-149-242.ngrok-free.app/generate\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"prompt\": \"Who is Sundar Pichai?\",\n",
    "    \"max_length\": 150,\n",
    "    \"temperature\": 0.7\n",
    "  }'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Formatted JSON Response (First Request, max_length: 150):**\n",
    "```json\n",
    "{\n",
    "  \"text\": \"?\\nSundar Pichai is an Indian American entrepreneur and business executive. He is the CEO of Google and its parent company Alphabet. Pichai was born in Chennai, India in 1972. He earned a bachelor' FBI Investigates Possible Hate Crime Against Sikh Man in California\\nSACRAMENTO, Calif. (AP) — The FBI is investigating a possible hate crime against a\",\n",
    "  \"generation_time\": 78.338,\n",
    "  \"tokens_generated\": 58,\n",
    "  \"tokens_per_second\": 0.7404,\n",
    "  \"speedup_factor\": 0.7243\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Formatted cURL Request (for max_length: 300):**\n",
    "```bash\n",
    "curl -X POST \"https://e7c0-35-194-149-242.ngrok-free.app/generate\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"prompt\": \"Who is Sundar Pichai?\",\n",
    "    \"max_length\": 300,\n",
    "    \"temperature\": 0.7\n",
    "  }'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Formatted JSON Response (Second Request, max_length: 300):**\n",
    "```json\n",
    "{\n",
    "  \"text\": \"?\\nSundar Pichai is an Indian entrepreneur and the CEO of Google. He was born in Chennai, India, in 1972. Pichai studied engineering at the Indian Institute of Technology, Kharagpur, and later went on to study at Stanford University in the United States. He joined Google in 2004 and has played a key role in the development of the company's products, including Google Chrome, Google\",\n",
    "  \"generation_time\": 77.681,\n",
    "  \"tokens_generated\": 65,\n",
    "  \"tokens_per_second\": 0.8368,\n",
    "  \"speedup_factor\": 0.8186\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Observations & Fixes:**\n",
    "   \n",
    "2. **Incorrectly Inserted Content:**  \n",
    "   - The first response unexpectedly contains a news snippet about an FBI investigation. This might be due to:\n",
    "     - Model hallucination.\n",
    "     - Overlapping training data.\n",
    "     - Need for better prompt engineering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Formatted cURL Request:**\n",
    "```bash\n",
    "curl -X POST \"https://e7c0-35-194-149-242.ngrok-free.app/generate\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"prompt\": \"Explain quantum physics\",\n",
    "    \"max_length\": 150,\n",
    "    \"temperature\": 0.7\n",
    "  }'\n",
    "```\n",
    "\n",
    "\n",
    "### **Formatted JSON Response:**\n",
    "```json\n",
    "{\n",
    "  \"text\": \" with a deck of cards\\nQuantum physics is a strange and counterintuitive theory that describes the behavior of matter and energy at a very small scale. It's difficult to explain, but this animated video uses a deck of cards to help illustrate some of its key concepts.\\nposted by zarq at 12:03 PM on April 7, 2016 [2 favorites]\\nThis is a great video! It's always impressive when\",\n",
    "  \"generation_time\": 76.318,\n",
    "  \"tokens_generated\": 68,\n",
    "  \"tokens_per_second\": 0.891,\n",
    "  \"speedup_factor\": 0.872\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Issues Observed:**\n",
    "1. **Irrelevant Content Injected:**  \n",
    "   - The response includes references to an animated video and a forum post (`\"posted by zarq at 12:03 PM on April 7, 2016\"`).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Medusa and without Medusa comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T11:11:32.693415Z",
     "iopub.status.busy": "2025-03-28T11:11:32.685376Z",
     "iopub.status.idle": "2025-03-28T12:24:14.081665Z",
     "shell.execute_reply": "2025-03-28T12:24:14.080575Z",
     "shell.execute_reply.started": "2025-03-28T11:11:32.693344Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1398]\n",
      "INFO:     Waiting for application startup.\n",
      "llama_model_loader: loaded meta data with 26 key-value pairs and 291 tensors from /kaggle/input/vicuna-1/gguf/default/1/vicuna-7b-v1.3-F16_KM.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Vicuna 7b v1.3\n",
      "llama_model_loader: - kv   3:                            general.version str              = v1.3\n",
      "llama_model_loader: - kv   4:                           general.basename str              = vicuna\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 7B\n",
      "llama_model_loader: - kv   6:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   7:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv   8:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   9:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv  10:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  12:                           llama.vocab_size u32              = 32000\n",
      "llama_model_loader: - kv  13:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  15:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  25:                          general.file_type u32              = 15\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens cache size = 3\n",
      "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = Vicuna 7b v1.3\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.file_type': '15', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.eos_token_id': '2', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.architecture': 'llama', 'llama.block_count': '32', 'tokenizer.ggml.padding_token_id': '0', 'general.basename': 'vicuna', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'default', 'llama.context_length': '2048', 'general.name': 'Vicuna 7b v1.3', 'llama.rope.dimension_count': '128', 'general.version': 'v1.3', 'general.type': 'model', 'general.size_label': '7B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.vocab_size': '32000'}\n",
      "Using fallback chat format: llama-2\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /    20 runs   (    0.08 ms per token, 12795.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1950.02 ms /     5 tokens (  390.00 ms per token,     2.56 tokens per second)\n",
      "llama_print_timings:        eval time =   14967.81 ms /    19 runs   (  787.78 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =   16939.71 ms /    24 tokens\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://dadf-35-194-149-242.ngrok-free.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      16.86 ms /   265 runs   (    0.06 ms per token, 15721.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  158592.01 ms /   265 runs   (  598.46 ms per token,     1.67 tokens per second)\n",
      "llama_print_timings:       total time =  158953.44 ms /   265 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /    50 runs   (    0.07 ms per token, 13939.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   37401.19 ms /    50 runs   (  748.02 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =   37453.74 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     763.14 ms /     1 runs   (  763.14 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     763.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     747.41 ms /     1 runs   (  747.41 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     747.88 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     766.96 ms /     1 runs   (  766.96 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     767.46 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     656.49 ms /     1 runs   (  656.49 ms per token,     1.52 tokens per second)\n",
      "llama_print_timings:       total time =     657.64 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.42 ms /     1 runs   (  789.42 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     789.79 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     735.27 ms /     1 runs   (  735.27 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     736.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     774.84 ms /     1 runs   (  774.84 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.20 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     716.74 ms /     1 runs   (  716.74 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =     716.76 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     799.14 ms /     1 runs   (  799.14 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     800.00 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.37 ms /     1 runs   (  764.37 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     764.74 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     721.86 ms /     1 runs   (  721.86 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =     722.38 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     753.40 ms /     1 runs   (  753.40 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     753.40 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     670.50 ms /     1 runs   (  670.50 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =     671.27 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     751.97 ms /     1 runs   (  751.97 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     752.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     709.83 ms /     1 runs   (  709.83 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =     709.86 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     932.00 ms /     1 runs   (  932.00 ms per token,     1.07 tokens per second)\n",
      "llama_print_timings:       total time =     932.54 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20833.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     908.43 ms /     1 runs   (  908.43 ms per token,     1.10 tokens per second)\n",
      "llama_print_timings:       total time =     908.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     791.11 ms /     1 runs   (  791.11 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     791.77 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     714.90 ms /     1 runs   (  714.90 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =     715.47 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 26315.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     677.85 ms /     1 runs   (  677.85 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =     677.84 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.24 ms /     1 runs   (  772.24 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     772.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.20 ms /     1 runs   (  762.20 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.57 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     739.42 ms /     1 runs   (  739.42 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     740.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     758.20 ms /     1 runs   (  758.20 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     758.93 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     690.82 ms /     1 runs   (  690.82 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =     690.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.84 ms /     1 runs   (  789.84 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     790.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     725.90 ms /     1 runs   (  725.90 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     726.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     725.70 ms /     1 runs   (  725.70 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     726.17 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.64 ms /     1 runs   (  789.64 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     790.34 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     757.08 ms /     1 runs   (  757.08 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     757.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     722.35 ms /     1 runs   (  722.35 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     722.47 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     739.54 ms /     1 runs   (  739.54 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     739.86 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     828.68 ms /     1 runs   (  828.68 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     829.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10989.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     747.77 ms /     1 runs   (  747.77 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     748.38 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     794.74 ms /     1 runs   (  794.74 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     795.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     710.19 ms /     1 runs   (  710.19 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =     713.20 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     745.59 ms /     1 runs   (  745.59 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     746.37 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10869.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     780.74 ms /     1 runs   (  780.74 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     781.29 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     746.36 ms /     1 runs   (  746.36 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     746.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     733.67 ms /     1 runs   (  733.67 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     733.95 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     725.91 ms /     1 runs   (  725.91 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     726.71 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     724.60 ms /     1 runs   (  724.60 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     725.30 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     715.32 ms /     1 runs   (  715.32 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =     717.47 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     726.12 ms /     1 runs   (  726.12 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     726.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      42.45 ms /   682 runs   (    0.06 ms per token, 16064.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  423094.31 ms /   682 runs   (  620.37 ms per token,     1.61 tokens per second)\n",
      "llama_print_timings:       total time =  424511.41 ms /   682 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     751.07 ms /     1 runs   (  751.07 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     751.40 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     749.30 ms /     1 runs   (  749.30 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     750.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     773.81 ms /     1 runs   (  773.81 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     774.63 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.49 ms /     1 runs   (  772.49 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     773.98 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     716.53 ms /     1 runs   (  716.53 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =     716.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     752.84 ms /     1 runs   (  752.84 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     753.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     732.38 ms /     1 runs   (  732.38 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     732.63 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     709.24 ms /     1 runs   (  709.24 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =     709.17 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     674.93 ms /     1 runs   (  674.93 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =     675.29 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     740.10 ms /     1 runs   (  740.10 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     740.20 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     748.54 ms /     1 runs   (  748.54 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     749.34 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     682.37 ms /     1 runs   (  682.37 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =     683.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     736.11 ms /     1 runs   (  736.11 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     738.07 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     754.76 ms /     1 runs   (  754.76 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     755.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     910.48 ms /     1 runs   (  910.48 ms per token,     1.10 tokens per second)\n",
      "llama_print_timings:       total time =     910.99 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     892.16 ms /     1 runs   (  892.16 ms per token,     1.12 tokens per second)\n",
      "llama_print_timings:       total time =     892.47 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 23255.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     672.06 ms /     1 runs   (  672.06 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =     672.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     752.79 ms /     1 runs   (  752.79 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     753.61 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 28571.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     755.35 ms /     1 runs   (  755.35 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     755.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     694.89 ms /     1 runs   (  694.89 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =     695.50 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     735.40 ms /     1 runs   (  735.40 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     737.46 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     733.94 ms /     1 runs   (  733.94 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     734.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     708.94 ms /     1 runs   (  708.94 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =     709.64 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     740.80 ms /     1 runs   (  740.80 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     741.17 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     748.15 ms /     1 runs   (  748.15 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     748.44 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     795.57 ms /     1 runs   (  795.57 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     796.22 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     802.41 ms /     1 runs   (  802.41 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     803.03 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     693.21 ms /     1 runs   (  693.21 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =     693.95 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     705.35 ms /     1 runs   (  705.35 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =     706.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     697.72 ms /     1 runs   (  697.72 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =     698.14 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.71 ms /     1 runs   (  762.71 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     763.19 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     782.75 ms /     1 runs   (  782.75 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     785.60 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     751.25 ms /     1 runs   (  751.25 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     751.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     729.01 ms /     1 runs   (  729.01 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     729.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     739.20 ms /     1 runs   (  739.20 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     740.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     727.71 ms /     1 runs   (  727.71 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     727.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     670.60 ms /     1 runs   (  670.60 ms per token,     1.49 tokens per second)\n",
      "llama_print_timings:       total time =     671.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     692.01 ms /     1 runs   (  692.01 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =     692.29 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.96 ms /     1 runs   (  772.96 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     773.63 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     779.91 ms /     1 runs   (  779.91 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     780.53 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     770.78 ms /     1 runs   (  770.78 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     771.38 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     736.66 ms /     1 runs   (  736.66 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     739.82 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     735.35 ms /     1 runs   (  735.35 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     735.73 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.82 ms /     1 runs   (  764.82 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     764.95 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     761.87 ms /     1 runs   (  761.87 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.21 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     745.39 ms /     1 runs   (  745.39 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     746.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     662.98 ms /     1 runs   (  662.98 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =     663.19 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     745.48 ms /     1 runs   (  745.48 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     747.51 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.72 ms /     1 runs   (  760.72 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     696.93 ms /     1 runs   (  696.93 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =     697.44 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     704.02 ms /     1 runs   (  704.02 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =     704.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10989.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     740.12 ms /     1 runs   (  740.12 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     741.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     748.53 ms /     1 runs   (  748.53 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     750.94 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     780.89 ms /     1 runs   (  780.89 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     781.99 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.11 ms /     1 runs   (  797.11 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     798.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     841.15 ms /     1 runs   (  841.15 ms per token,     1.19 tokens per second)\n",
      "llama_print_timings:       total time =     841.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.12 ms /     1 runs   (    0.12 ms per token,  8547.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     885.52 ms /     1 runs   (  885.52 ms per token,     1.13 tokens per second)\n",
      "llama_print_timings:       total time =     886.32 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     958.76 ms /     1 runs   (  958.76 ms per token,     1.04 tokens per second)\n",
      "llama_print_timings:       total time =     959.35 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     961.26 ms /     1 runs   (  961.26 ms per token,     1.04 tokens per second)\n",
      "llama_print_timings:       total time =     961.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     796.11 ms /     1 runs   (  796.11 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     796.94 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     819.44 ms /     1 runs   (  819.44 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     821.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     781.74 ms /     1 runs   (  781.74 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     782.52 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     785.41 ms /     1 runs   (  785.41 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     768.79 ms /     1 runs   (  768.79 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     769.77 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     754.29 ms /     1 runs   (  754.29 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     754.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     768.79 ms /     1 runs   (  768.79 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     769.38 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     839.60 ms /     1 runs   (  839.60 ms per token,     1.19 tokens per second)\n",
      "llama_print_timings:       total time =     840.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     788.31 ms /     1 runs   (  788.31 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     867.98 ms /     1 runs   (  867.98 ms per token,     1.15 tokens per second)\n",
      "llama_print_timings:       total time =     868.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     807.73 ms /     1 runs   (  807.73 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     808.42 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12345.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     818.33 ms /     1 runs   (  818.33 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     819.12 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     769.90 ms /     1 runs   (  769.90 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     770.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     840.38 ms /     1 runs   (  840.38 ms per token,     1.19 tokens per second)\n",
      "llama_print_timings:       total time =     840.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     749.56 ms /     1 runs   (  749.56 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     750.73 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     783.27 ms /     1 runs   (  783.27 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     783.84 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25641.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     765.80 ms /     1 runs   (  765.80 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     766.47 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     802.51 ms /     1 runs   (  802.51 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     803.07 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     788.12 ms /     1 runs   (  788.12 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     765.33 ms /     1 runs   (  765.33 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     766.29 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     774.82 ms /     1 runs   (  774.82 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.74 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     869.44 ms /     1 runs   (  869.44 ms per token,     1.15 tokens per second)\n",
      "llama_print_timings:       total time =     870.19 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10869.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     791.28 ms /     1 runs   (  791.28 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     791.64 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     781.48 ms /     1 runs   (  781.48 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     782.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     755.94 ms /     1 runs   (  755.94 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     757.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.95 ms /     1 runs   (  772.95 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     773.64 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 24390.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     780.88 ms /     1 runs   (  780.88 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     781.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.30 ms /     1 runs   (  760.30 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     761.12 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     766.87 ms /     1 runs   (  766.87 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     767.23 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10416.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     796.44 ms /     1 runs   (  796.44 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     797.45 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     779.74 ms /     1 runs   (  779.74 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     780.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.12 ms /     1 runs   (    0.12 ms per token,  8264.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     773.93 ms /     1 runs   (  773.93 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.02 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.09 ms /     1 runs   (  762.09 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.37 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11494.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     766.50 ms /     1 runs   (  766.50 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     767.50 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 27777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.30 ms /     1 runs   (  789.30 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     789.98 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     776.80 ms /     1 runs   (  776.80 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     779.25 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     814.56 ms /     1 runs   (  814.56 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     815.36 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     825.60 ms /     1 runs   (  825.60 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     826.72 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     982.41 ms /     1 runs   (  982.41 ms per token,     1.02 tokens per second)\n",
      "llama_print_timings:       total time =     983.46 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     977.38 ms /     1 runs   (  977.38 ms per token,     1.02 tokens per second)\n",
      "llama_print_timings:       total time =     978.66 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     826.49 ms /     1 runs   (  826.49 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     826.72 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     768.03 ms /     1 runs   (  768.03 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     768.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     803.03 ms /     1 runs   (  803.03 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     803.68 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     751.22 ms /     1 runs   (  751.22 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     752.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     786.80 ms /     1 runs   (  786.80 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.50 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     818.61 ms /     1 runs   (  818.61 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     823.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     756.42 ms /     1 runs   (  756.42 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     757.38 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10989.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     779.53 ms /     1 runs   (  779.53 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     780.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     717.17 ms /     1 runs   (  717.17 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =     717.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.75 ms /     1 runs   (  760.75 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     761.30 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     794.20 ms /     1 runs   (  794.20 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     794.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     743.07 ms /     1 runs   (  743.07 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     743.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25641.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     812.30 ms /     1 runs   (  812.30 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     812.94 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11111.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     807.69 ms /     1 runs   (  807.69 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     808.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     791.17 ms /     1 runs   (  791.17 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     791.84 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     768.14 ms /     1 runs   (  768.14 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     770.53 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     783.51 ms /     1 runs   (  783.51 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     783.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.12 ms /     1 runs   (    0.12 ms per token,  8403.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     807.18 ms /     1 runs   (  807.18 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     808.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     761.54 ms /     1 runs   (  761.54 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  8928.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     749.81 ms /     1 runs   (  749.81 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     750.92 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     822.05 ms /     1 runs   (  822.05 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     822.80 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     753.45 ms /     1 runs   (  753.45 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     753.54 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     788.07 ms /     1 runs   (  788.07 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.98 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     795.12 ms /     1 runs   (  795.12 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     795.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     778.40 ms /     1 runs   (  778.40 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     779.45 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.53 ms /     1 runs   (  772.53 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     773.65 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     732.65 ms /     1 runs   (  732.65 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     733.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     728.03 ms /     1 runs   (  728.03 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     728.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     774.66 ms /     1 runs   (  774.66 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.74 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     739.67 ms /     1 runs   (  739.67 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     741.25 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.18 ms /     1 runs   (  760.18 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     763.93 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     833.38 ms /     1 runs   (  833.38 ms per token,     1.20 tokens per second)\n",
      "llama_print_timings:       total time =     834.18 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     786.72 ms /     1 runs   (  786.72 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     787.20 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12345.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     769.97 ms /     1 runs   (  769.97 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     771.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     794.57 ms /     1 runs   (  794.57 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     795.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     808.33 ms /     1 runs   (  808.33 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     809.20 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     805.04 ms /     1 runs   (  805.04 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     807.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     795.62 ms /     1 runs   (  795.62 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     795.89 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     805.15 ms /     1 runs   (  805.15 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     805.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     934.65 ms /     1 runs   (  934.65 ms per token,     1.07 tokens per second)\n",
      "llama_print_timings:       total time =     935.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    1001.78 ms /     1 runs   ( 1001.78 ms per token,     1.00 tokens per second)\n",
      "llama_print_timings:       total time =    1002.84 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     863.94 ms /     1 runs   (  863.94 ms per token,     1.16 tokens per second)\n",
      "llama_print_timings:       total time =     866.23 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     802.96 ms /     1 runs   (  802.96 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     803.64 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     845.60 ms /     1 runs   (  845.60 ms per token,     1.18 tokens per second)\n",
      "llama_print_timings:       total time =     846.18 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11363.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     738.77 ms /     1 runs   (  738.77 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     739.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      16.64 ms /   264 runs   (    0.06 ms per token, 15869.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  200994.14 ms /   264 runs   (  761.34 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =  201360.41 ms /   264 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     786.83 ms /     1 runs   (  786.83 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     787.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     807.13 ms /     1 runs   (  807.13 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     807.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     756.02 ms /     1 runs   (  756.02 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     757.12 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.99 ms /     1 runs   (  797.99 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     798.52 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     796.79 ms /     1 runs   (  796.79 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     797.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     819.96 ms /     1 runs   (  819.96 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     822.39 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     751.14 ms /     1 runs   (  751.14 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     751.36 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     780.18 ms /     1 runs   (  780.18 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     781.25 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  8928.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     798.26 ms /     1 runs   (  798.26 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     799.40 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     778.76 ms /     1 runs   (  778.76 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     779.60 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.85 ms /     1 runs   (  797.85 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     798.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     766.78 ms /     1 runs   (  766.78 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     766.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     769.97 ms /     1 runs   (  769.97 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     770.96 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     800.11 ms /     1 runs   (  800.11 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     800.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     839.52 ms /     1 runs   (  839.52 ms per token,     1.19 tokens per second)\n",
      "llama_print_timings:       total time =     840.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     750.55 ms /     1 runs   (  750.55 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     751.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     828.01 ms /     1 runs   (  828.01 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     830.30 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     793.99 ms /     1 runs   (  793.99 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     796.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     827.51 ms /     1 runs   (  827.51 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     828.97 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.75 ms /     1 runs   (  764.75 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     765.93 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     718.82 ms /     1 runs   (  718.82 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =     721.35 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     793.49 ms /     1 runs   (  793.49 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     793.89 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     802.97 ms /     1 runs   (  802.97 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     804.64 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     763.75 ms /     1 runs   (  763.75 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     764.86 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     821.07 ms /     1 runs   (  821.07 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     821.79 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     776.63 ms /     1 runs   (  776.63 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     777.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     808.60 ms /     1 runs   (  808.60 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     809.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     828.02 ms /     1 runs   (  828.02 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     829.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.10 ms /     1 runs   (  797.10 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     797.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     749.36 ms /     1 runs   (  749.36 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     749.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     752.64 ms /     1 runs   (  752.64 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     753.07 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     758.49 ms /     1 runs   (  758.49 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     758.90 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     800.19 ms /     1 runs   (  800.19 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     800.35 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     822.65 ms /     1 runs   (  822.65 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     823.46 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     744.35 ms /     1 runs   (  744.35 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     747.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     1 runs   (    0.21 ms per token,  4807.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     786.63 ms /     1 runs   (  786.63 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     787.85 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     819.69 ms /     1 runs   (  819.69 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     820.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.03 ms /     1 runs   (  760.03 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     760.65 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 23255.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     907.64 ms /     1 runs   (  907.64 ms per token,     1.10 tokens per second)\n",
      "llama_print_timings:       total time =     908.85 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     997.13 ms /     1 runs   (  997.13 ms per token,     1.00 tokens per second)\n",
      "llama_print_timings:       total time =     998.30 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     936.01 ms /     1 runs   (  936.01 ms per token,     1.07 tokens per second)\n",
      "llama_print_timings:       total time =     936.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     812.15 ms /     1 runs   (  812.15 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     812.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     753.36 ms /     1 runs   (  753.36 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     755.21 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     804.89 ms /     1 runs   (  804.89 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     805.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     779.08 ms /     1 runs   (  779.08 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     780.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     845.42 ms /     1 runs   (  845.42 ms per token,     1.18 tokens per second)\n",
      "llama_print_timings:       total time =     845.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     740.79 ms /     1 runs   (  740.79 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     741.42 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     799.99 ms /     1 runs   (  799.99 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     800.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 28571.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     805.82 ms /     1 runs   (  805.82 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     808.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     761.35 ms /     1 runs   (  761.35 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     808.74 ms /     1 runs   (  808.74 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     809.82 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     834.88 ms /     1 runs   (  834.88 ms per token,     1.20 tokens per second)\n",
      "llama_print_timings:       total time =     835.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.45 ms /     1 runs   (  797.45 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     798.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.03 ms /     1 runs   (  789.03 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     790.22 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 27027.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     776.44 ms /     1 runs   (  776.44 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     777.23 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.50 ms /     1 runs   (  762.50 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     764.82 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 27777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     792.02 ms /     1 runs   (  792.02 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     794.27 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     740.02 ms /     1 runs   (  740.02 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     740.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     773.85 ms /     1 runs   (  773.85 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     774.82 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     814.15 ms /     1 runs   (  814.15 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     814.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 27027.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     783.09 ms /     1 runs   (  783.09 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     785.12 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10869.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     792.90 ms /     1 runs   (  792.90 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     794.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     800.70 ms /     1 runs   (  800.70 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     801.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     765.18 ms /     1 runs   (  765.18 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     765.73 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     876.17 ms /     1 runs   (  876.17 ms per token,     1.14 tokens per second)\n",
      "llama_print_timings:       total time =     876.92 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.12 ms /     1 runs   (    0.12 ms per token,  8474.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     821.58 ms /     1 runs   (  821.58 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     822.87 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     812.14 ms /     1 runs   (  812.14 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     814.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     773.74 ms /     1 runs   (  773.74 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     774.86 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     777.31 ms /     1 runs   (  777.31 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     777.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     783.11 ms /     1 runs   (  783.11 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     784.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     834.80 ms /     1 runs   (  834.80 ms per token,     1.20 tokens per second)\n",
      "llama_print_timings:       total time =     835.87 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     829.06 ms /     1 runs   (  829.06 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     829.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     787.35 ms /     1 runs   (  787.35 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.91 ms /     1 runs   (  789.91 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     790.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     821.33 ms /     1 runs   (  821.33 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     822.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     779.46 ms /     1 runs   (  779.46 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     780.27 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     841.69 ms /     1 runs   (  841.69 ms per token,     1.19 tokens per second)\n",
      "llama_print_timings:       total time =     842.88 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     799.08 ms /     1 runs   (  799.08 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     800.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     920.82 ms /     1 runs   (  920.82 ms per token,     1.09 tokens per second)\n",
      "llama_print_timings:       total time =     921.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    1007.40 ms /     1 runs   ( 1007.40 ms per token,     0.99 tokens per second)\n",
      "llama_print_timings:       total time =    1008.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     874.89 ms /     1 runs   (  874.89 ms per token,     1.14 tokens per second)\n",
      "llama_print_timings:       total time =     877.32 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     778.37 ms /     1 runs   (  778.37 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     780.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     822.38 ms /     1 runs   (  822.38 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     824.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     736.80 ms /     1 runs   (  736.80 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     737.53 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12345.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     811.21 ms /     1 runs   (  811.21 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     813.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     792.25 ms /     1 runs   (  792.25 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     792.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     690.35 ms /     1 runs   (  690.35 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =     691.45 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     791.05 ms /     1 runs   (  791.05 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     791.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     889.69 ms /     1 runs   (  889.69 ms per token,     1.12 tokens per second)\n",
      "llama_print_timings:       total time =     892.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20833.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     825.60 ms /     1 runs   (  825.60 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     827.65 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     821.12 ms /     1 runs   (  821.12 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     821.67 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     784.30 ms /     1 runs   (  784.30 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     785.17 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     811.01 ms /     1 runs   (  811.01 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     812.71 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     821.11 ms /     1 runs   (  821.11 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     826.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     796.56 ms /     1 runs   (  796.56 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     797.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.12 ms /     1 runs   (    0.12 ms per token,  8196.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     796.21 ms /     1 runs   (  796.21 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     797.50 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     806.54 ms /     1 runs   (  806.54 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     807.57 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     810.64 ms /     1 runs   (  810.64 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     811.30 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.45 ms /     1 runs   (  789.45 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     790.71 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10752.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     787.25 ms /     1 runs   (  787.25 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     787.82 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     801.14 ms /     1 runs   (  801.14 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     801.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     778.92 ms /     1 runs   (  778.92 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     780.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11494.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     803.26 ms /     1 runs   (  803.26 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     804.50 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     809.23 ms /     1 runs   (  809.23 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     810.52 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     793.42 ms /     1 runs   (  793.42 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     794.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     804.75 ms /     1 runs   (  804.75 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     805.60 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.41 ms /     1 runs   (  790.41 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     791.79 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     773.99 ms /     1 runs   (  773.99 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.00 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     814.85 ms /     1 runs   (  814.85 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     815.44 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.54 ms /     1 runs   (  790.54 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     790.77 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     792.26 ms /     1 runs   (  792.26 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     793.52 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25641.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.82 ms /     1 runs   (  790.82 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     792.86 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     801.64 ms /     1 runs   (  801.64 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     801.88 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     777.15 ms /     1 runs   (  777.15 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     778.52 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     747.99 ms /     1 runs   (  747.99 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     749.00 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     827.39 ms /     1 runs   (  827.39 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     827.99 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     782.13 ms /     1 runs   (  782.13 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     783.02 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     831.07 ms /     1 runs   (  831.07 ms per token,     1.20 tokens per second)\n",
      "llama_print_timings:       total time =     832.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     973.02 ms /     1 runs   (  973.02 ms per token,     1.03 tokens per second)\n",
      "llama_print_timings:       total time =     973.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     967.46 ms /     1 runs   (  967.46 ms per token,     1.03 tokens per second)\n",
      "llama_print_timings:       total time =     968.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     893.26 ms /     1 runs   (  893.26 ms per token,     1.12 tokens per second)\n",
      "llama_print_timings:       total time =     893.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     799.44 ms /     1 runs   (  799.44 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     800.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.98 ms /     1 runs   (  760.98 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     787.59 ms /     1 runs   (  787.59 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10309.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     842.76 ms /     1 runs   (  842.76 ms per token,     1.19 tokens per second)\n",
      "llama_print_timings:       total time =     844.03 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     801.34 ms /     1 runs   (  801.34 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     802.90 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     778.07 ms /     1 runs   (  778.07 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     780.00 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     806.62 ms /     1 runs   (  806.62 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     807.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10638.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     804.38 ms /     1 runs   (  804.38 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     805.66 ms /     1 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     14.102.161.98:0 - \"POST /compare HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      17.17 ms /   263 runs   (    0.07 ms per token, 15316.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  180009.76 ms /   263 runs   (  684.45 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =  180356.88 ms /   263 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /   217 runs   (    0.06 ms per token, 16687.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  125286.57 ms /   217 runs   (  577.36 ms per token,     1.73 tokens per second)\n",
      "llama_print_timings:       total time =  125555.52 ms /   217 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      43.80 ms /   681 runs   (    0.06 ms per token, 15548.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  467053.76 ms /   681 runs   (  685.84 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =  468456.63 ms /   681 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     706.00 ms /     1 runs   (  706.00 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =     706.68 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     699.70 ms /     1 runs   (  699.70 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =     703.25 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     663.88 ms /     1 runs   (  663.88 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =     664.65 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     604.46 ms /     1 runs   (  604.46 ms per token,     1.65 tokens per second)\n",
      "llama_print_timings:       total time =     605.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      22.45 ms /   327 runs   (    0.07 ms per token, 14563.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  191326.83 ms /   327 runs   (  585.10 ms per token,     1.71 tokens per second)\n",
      "llama_print_timings:       total time =  191796.32 ms /   327 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     14.102.161.98:0 - \"POST /compare HTTP/1.1\" 422 Unprocessable Entity\n",
      "INFO:     14.102.161.98:0 - \"POST /compare HTTP/1.1\" 422 Unprocessable Entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      20.89 ms /   326 runs   (    0.06 ms per token, 15604.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  195076.38 ms /   326 runs   (  598.39 ms per token,     1.67 tokens per second)\n",
      "llama_print_timings:       total time =  195558.81 ms /   326 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.08 ms /     1 runs   (  790.08 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     791.23 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11494.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     836.69 ms /     1 runs   (  836.69 ms per token,     1.20 tokens per second)\n",
      "llama_print_timings:       total time =     838.00 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  9009.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     827.12 ms /     1 runs   (  827.12 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     828.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     759.52 ms /     1 runs   (  759.52 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     760.25 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /    50 runs   (    0.07 ms per token, 13609.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   40325.43 ms /    50 runs   (  806.51 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =   40378.13 ms /    50 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     14.102.161.98:0 - \"POST /generate/normal HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      44.72 ms /   680 runs   (    0.07 ms per token, 15207.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  416398.15 ms /   680 runs   (  612.35 ms per token,     1.63 tokens per second)\n",
      "llama_print_timings:       total time =  417804.25 ms /   680 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      20.64 ms /   325 runs   (    0.06 ms per token, 15742.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  193180.42 ms /   325 runs   (  594.40 ms per token,     1.68 tokens per second)\n",
      "llama_print_timings:       total time =  193665.82 ms /   325 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       8.72 ms /   129 runs   (    0.07 ms per token, 14788.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   71523.19 ms /   129 runs   (  554.44 ms per token,     1.80 tokens per second)\n",
      "llama_print_timings:       total time =   71663.26 ms /   129 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.02 ms /     1 runs   (  764.02 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     765.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  9174.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     784.20 ms /     1 runs   (  784.20 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     784.84 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     728.60 ms /     1 runs   (  728.60 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     729.50 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  8928.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     707.20 ms /     1 runs   (  707.20 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =     708.02 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     756.54 ms /     1 runs   (  756.54 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     757.37 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     833.96 ms /     1 runs   (  833.96 ms per token,     1.20 tokens per second)\n",
      "llama_print_timings:       total time =     834.80 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10416.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     974.95 ms /     1 runs   (  974.95 ms per token,     1.03 tokens per second)\n",
      "llama_print_timings:       total time =     975.82 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     963.98 ms /     1 runs   (  963.98 ms per token,     1.04 tokens per second)\n",
      "llama_print_timings:       total time =     964.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     862.85 ms /     1 runs   (  862.85 ms per token,     1.16 tokens per second)\n",
      "llama_print_timings:       total time =     863.21 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     753.45 ms /     1 runs   (  753.45 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     753.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     782.27 ms /     1 runs   (  782.27 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     782.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     781.03 ms /     1 runs   (  781.03 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     781.18 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     775.12 ms /     1 runs   (  775.12 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     767.02 ms /     1 runs   (  767.02 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     767.64 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     750.95 ms /     1 runs   (  750.95 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     750.95 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     783.99 ms /     1 runs   (  783.99 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     784.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     741.62 ms /     1 runs   (  741.62 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     741.97 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     730.88 ms /     1 runs   (  730.88 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     730.80 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     750.32 ms /     1 runs   (  750.32 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     750.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     755.35 ms /     1 runs   (  755.35 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     755.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     754.05 ms /     1 runs   (  754.05 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     755.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     784.70 ms /     1 runs   (  784.70 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     786.53 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     782.87 ms /     1 runs   (  782.87 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     784.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     780.86 ms /     1 runs   (  780.86 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     781.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     750.11 ms /     1 runs   (  750.11 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     750.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12345.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     746.14 ms /     1 runs   (  746.14 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     746.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     807.16 ms /     1 runs   (  807.16 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     807.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  9174.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     738.91 ms /     1 runs   (  738.91 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     739.84 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     741.43 ms /     1 runs   (  741.43 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     741.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     721.36 ms /     1 runs   (  721.36 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =     723.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.44 ms /     1 runs   (  797.44 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     798.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     775.99 ms /     1 runs   (  775.99 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     776.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     770.44 ms /     1 runs   (  770.44 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     771.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     660.28 ms /     1 runs   (  660.28 ms per token,     1.51 tokens per second)\n",
      "llama_print_timings:       total time =     660.74 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     784.69 ms /     1 runs   (  784.69 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     784.78 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     774.81 ms /     1 runs   (  774.81 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     777.26 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.12 ms /     1 runs   (    0.12 ms per token,  8403.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     743.47 ms /     1 runs   (  743.47 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     744.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10752.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     753.63 ms /     1 runs   (  753.63 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     754.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     709.34 ms /     1 runs   (  709.34 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =     710.93 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     773.76 ms /     1 runs   (  773.76 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     774.52 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     739.41 ms /     1 runs   (  739.41 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     739.79 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     808.05 ms /     1 runs   (  808.05 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     809.82 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     820.86 ms /     1 runs   (  820.86 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     822.27 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     747.97 ms /     1 runs   (  747.97 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     748.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.21 ms /     1 runs   (  764.21 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     764.86 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     783.55 ms /     1 runs   (  783.55 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     784.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     717.66 ms /     1 runs   (  717.66 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =     717.82 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     901.48 ms /     1 runs   (  901.48 ms per token,     1.11 tokens per second)\n",
      "llama_print_timings:       total time =     902.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     886.94 ms /     1 runs   (  886.94 ms per token,     1.13 tokens per second)\n",
      "llama_print_timings:       total time =     889.18 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     968.98 ms /     1 runs   (  968.98 ms per token,     1.03 tokens per second)\n",
      "llama_print_timings:       total time =     969.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.65 ms /     1 runs   (  760.65 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     760.78 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.42 ms /     1 runs   (  772.42 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     772.94 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 24390.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     808.59 ms /     1 runs   (  808.59 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     809.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     776.00 ms /     1 runs   (  776.00 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     776.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     816.83 ms /     1 runs   (  816.83 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     817.72 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     794.18 ms /     1 runs   (  794.18 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     794.97 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     802.71 ms /     1 runs   (  802.71 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     802.93 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     803.13 ms /     1 runs   (  803.13 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     803.71 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.28 ms /     1 runs   (  764.28 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     764.84 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     806.68 ms /     1 runs   (  806.68 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     807.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     791.38 ms /     1 runs   (  791.38 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     791.76 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     755.53 ms /     1 runs   (  755.53 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     755.68 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     741.10 ms /     1 runs   (  741.10 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     741.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     777.85 ms /     1 runs   (  777.85 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     778.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.08 ms /     1 runs   (  790.08 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     790.37 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.40 ms /     1 runs   (  797.40 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     798.30 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     710.75 ms /     1 runs   (  710.75 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =     711.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.34 ms /     1 runs   (  762.34 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     763.19 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     721.16 ms /     1 runs   (  721.16 ms per token,     1.39 tokens per second)\n",
      "llama_print_timings:       total time =     721.89 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     746.92 ms /     1 runs   (  746.92 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     747.32 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     767.90 ms /     1 runs   (  767.90 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     769.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 24390.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.44 ms /     1 runs   (  762.44 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     807.43 ms /     1 runs   (  807.43 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     808.12 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     753.60 ms /     1 runs   (  753.60 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     754.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10869.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     725.09 ms /     1 runs   (  725.09 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     730.26 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.17 ms /     1 runs   (  762.17 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     716.76 ms /     1 runs   (  716.76 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =     717.46 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     767.03 ms /     1 runs   (  767.03 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     767.40 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     769.43 ms /     1 runs   (  769.43 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     771.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     774.72 ms /     1 runs   (  774.72 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.26 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.06 ms /     1 runs   (  762.06 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.40 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     739.61 ms /     1 runs   (  739.61 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     740.29 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 23809.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     791.23 ms /     1 runs   (  791.23 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     791.25 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     748.51 ms /     1 runs   (  748.51 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     749.18 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     754.06 ms /     1 runs   (  754.06 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     756.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.04 ms /     1 runs   (  790.04 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     791.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     725.72 ms /     1 runs   (  725.72 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     726.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     742.44 ms /     1 runs   (  742.44 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     743.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.63 ms /     1 runs   (  764.63 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     765.38 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     1 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     913.80 ms /     1 runs   (  913.80 ms per token,     1.09 tokens per second)\n",
      "llama_print_timings:       total time =     915.32 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     877.18 ms /     1 runs   (  877.18 ms per token,     1.14 tokens per second)\n",
      "llama_print_timings:       total time =     877.34 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     867.01 ms /     1 runs   (  867.01 ms per token,     1.15 tokens per second)\n",
      "llama_print_timings:       total time =     867.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     763.00 ms /     1 runs   (  763.00 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     763.23 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.20 ms /     1 runs   (  764.20 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     765.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     774.20 ms /     1 runs   (  774.20 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     777.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     769.57 ms /     1 runs   (  769.57 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     769.93 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     781.02 ms /     1 runs   (  781.02 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     781.87 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20833.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     810.47 ms /     1 runs   (  810.47 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     811.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     775.48 ms /     1 runs   (  775.48 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     776.04 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     793.05 ms /     1 runs   (  793.05 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     795.04 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     712.14 ms /     1 runs   (  712.14 ms per token,     1.40 tokens per second)\n",
      "llama_print_timings:       total time =     712.42 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20833.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     768.07 ms /     1 runs   (  768.07 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     768.09 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.16 ms /     1 runs   (  762.16 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     763.21 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     756.29 ms /     1 runs   (  756.29 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     756.77 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11363.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.19 ms /     1 runs   (  790.19 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     791.20 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10638.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     767.14 ms /     1 runs   (  767.14 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     767.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     788.60 ms /     1 runs   (  788.60 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.98 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     767.92 ms /     1 runs   (  767.92 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     768.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     676.17 ms /     1 runs   (  676.17 ms per token,     1.48 tokens per second)\n",
      "llama_print_timings:       total time =     676.67 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     747.41 ms /     1 runs   (  747.41 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     748.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     836.74 ms /     1 runs   (  836.74 ms per token,     1.20 tokens per second)\n",
      "llama_print_timings:       total time =     837.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     800.91 ms /     1 runs   (  800.91 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     801.90 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.50 ms /     1 runs   (  789.50 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     790.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     730.15 ms /     1 runs   (  730.15 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     730.71 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     756.17 ms /     1 runs   (  756.17 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     756.46 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.36 ms /     1 runs   (  772.36 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     772.51 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /   128 runs   (    0.06 ms per token, 15567.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   97678.18 ms /   128 runs   (  763.11 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =   97812.54 ms /   128 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     745.24 ms /     1 runs   (  745.24 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     746.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     768.42 ms /     1 runs   (  768.42 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     768.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     753.60 ms /     1 runs   (  753.60 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     753.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 26315.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     740.17 ms /     1 runs   (  740.17 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     740.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     773.01 ms /     1 runs   (  773.01 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     774.14 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     761.12 ms /     1 runs   (  761.12 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.97 ms /     1 runs   (  762.97 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     763.94 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     851.29 ms /     1 runs   (  851.29 ms per token,     1.17 tokens per second)\n",
      "llama_print_timings:       total time =     852.63 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     766.03 ms /     1 runs   (  766.03 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     767.77 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.96 ms /     1 runs   (  797.96 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     798.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10989.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     706.01 ms /     1 runs   (  706.01 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =     707.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     748.75 ms /     1 runs   (  748.75 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     749.74 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     722.18 ms /     1 runs   (  722.18 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     722.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.07 ms /     1 runs   (  797.07 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     797.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     821.84 ms /     1 runs   (  821.84 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     822.93 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    1035.12 ms /     1 runs   ( 1035.12 ms per token,     0.97 tokens per second)\n",
      "llama_print_timings:       total time =    1035.72 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     919.63 ms /     1 runs   (  919.63 ms per token,     1.09 tokens per second)\n",
      "llama_print_timings:       total time =     920.46 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     847.74 ms /     1 runs   (  847.74 ms per token,     1.18 tokens per second)\n",
      "llama_print_timings:       total time =     849.19 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     775.86 ms /     1 runs   (  775.86 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     776.07 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     815.99 ms /     1 runs   (  815.99 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     816.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.15 ms /     1 runs   (  764.15 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     770.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     749.21 ms /     1 runs   (  749.21 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     749.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10752.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     682.34 ms /     1 runs   (  682.34 ms per token,     1.47 tokens per second)\n",
      "llama_print_timings:       total time =     683.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token,  9803.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.60 ms /     1 runs   (  790.60 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     791.74 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     733.83 ms /     1 runs   (  733.83 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     735.27 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20833.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     710.39 ms /     1 runs   (  710.39 ms per token,     1.41 tokens per second)\n",
      "llama_print_timings:       total time =     711.50 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     758.18 ms /     1 runs   (  758.18 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     758.47 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     799.75 ms /     1 runs   (  799.75 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     799.95 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.09 ms /     1 runs   (  764.09 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     765.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 26315.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     793.10 ms /     1 runs   (  793.10 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     793.88 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.86 ms /     1 runs   (  760.86 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     761.60 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     724.75 ms /     1 runs   (  724.75 ms per token,     1.38 tokens per second)\n",
      "llama_print_timings:       total time =     725.18 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     851.23 ms /     1 runs   (  851.23 ms per token,     1.17 tokens per second)\n",
      "llama_print_timings:       total time =     851.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.81 ms /     1 runs   (  760.81 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     761.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     688.54 ms /     1 runs   (  688.54 ms per token,     1.45 tokens per second)\n",
      "llama_print_timings:       total time =     689.85 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     801.91 ms /     1 runs   (  801.91 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     802.23 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.23 ms /     1 runs   (  790.23 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     791.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     801.88 ms /     1 runs   (  801.88 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     802.87 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     741.45 ms /     1 runs   (  741.45 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     742.12 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     787.03 ms /     1 runs   (  787.03 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.29 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     802.77 ms /     1 runs   (  802.77 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     803.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     808.47 ms /     1 runs   (  808.47 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     810.61 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     830.22 ms /     1 runs   (  830.22 ms per token,     1.20 tokens per second)\n",
      "llama_print_timings:       total time =     831.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     798.79 ms /     1 runs   (  798.79 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     799.44 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     799.54 ms /     1 runs   (  799.54 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     800.12 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     771.67 ms /     1 runs   (  771.67 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     772.29 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     742.75 ms /     1 runs   (  742.75 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     743.54 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     730.76 ms /     1 runs   (  730.76 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     731.37 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     786.33 ms /     1 runs   (  786.33 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     786.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     777.36 ms /     1 runs   (  777.36 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     778.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20833.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     771.78 ms /     1 runs   (  771.78 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     773.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     793.70 ms /     1 runs   (  793.70 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     798.18 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 24390.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     734.14 ms /     1 runs   (  734.14 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     734.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  9090.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     820.25 ms /     1 runs   (  820.25 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     821.37 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     730.93 ms /     1 runs   (  730.93 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     731.63 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     793.32 ms /     1 runs   (  793.32 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     794.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     953.65 ms /     1 runs   (  953.65 ms per token,     1.05 tokens per second)\n",
      "llama_print_timings:       total time =     954.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     912.47 ms /     1 runs   (  912.47 ms per token,     1.10 tokens per second)\n",
      "llama_print_timings:       total time =     917.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     813.55 ms /     1 runs   (  813.55 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     817.19 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     787.47 ms /     1 runs   (  787.47 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.02 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25641.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     765.89 ms /     1 runs   (  765.89 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     766.89 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     796.41 ms /     1 runs   (  796.41 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     796.78 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     820.88 ms /     1 runs   (  820.88 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     821.66 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.30 ms /     1 runs   (  764.30 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     766.34 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     802.43 ms /     1 runs   (  802.43 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     803.60 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     848.15 ms /     1 runs   (  848.15 ms per token,     1.18 tokens per second)\n",
      "llama_print_timings:       total time =     850.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     770.91 ms /     1 runs   (  770.91 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     772.03 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     815.16 ms /     1 runs   (  815.16 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     816.02 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     770.97 ms /     1 runs   (  770.97 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     771.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     800.77 ms /     1 runs   (  800.77 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     801.74 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     741.00 ms /     1 runs   (  741.00 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     741.76 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.16 ms /     1 runs   (  764.16 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     766.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     737.42 ms /     1 runs   (  737.42 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     740.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     1 runs   (    1.40 ms per token,   713.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     758.60 ms /     1 runs   (  758.60 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     760.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     786.52 ms /     1 runs   (  786.52 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     787.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     794.74 ms /     1 runs   (  794.74 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     795.96 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11494.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     763.74 ms /     1 runs   (  763.74 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     764.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     781.17 ms /     1 runs   (  781.17 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     784.51 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     784.26 ms /     1 runs   (  784.26 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     785.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     749.96 ms /     1 runs   (  749.96 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     751.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     793.39 ms /     1 runs   (  793.39 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     793.73 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     756.72 ms /     1 runs   (  756.72 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     757.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     821.27 ms /     1 runs   (  821.27 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     824.20 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     777.93 ms /     1 runs   (  777.93 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     778.94 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12345.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     750.26 ms /     1 runs   (  750.26 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     750.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10309.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.50 ms /     1 runs   (  764.50 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     765.80 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     806.75 ms /     1 runs   (  806.75 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     807.14 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     769.30 ms /     1 runs   (  769.30 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     769.85 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     757.23 ms /     1 runs   (  757.23 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     758.30 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     735.32 ms /     1 runs   (  735.32 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     736.42 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10309.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     774.47 ms /     1 runs   (  774.47 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.39 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     740.98 ms /     1 runs   (  740.98 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     741.96 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     786.10 ms /     1 runs   (  786.10 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     787.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.22 ms /     1 runs   (  772.22 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     772.99 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     771.53 ms /     1 runs   (  771.53 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     772.47 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     803.07 ms /     1 runs   (  803.07 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     803.67 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     831.51 ms /     1 runs   (  831.51 ms per token,     1.20 tokens per second)\n",
      "llama_print_timings:       total time =     831.99 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     951.79 ms /     1 runs   (  951.79 ms per token,     1.05 tokens per second)\n",
      "llama_print_timings:       total time =     952.22 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     969.93 ms /     1 runs   (  969.93 ms per token,     1.03 tokens per second)\n",
      "llama_print_timings:       total time =     971.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     810.03 ms /     1 runs   (  810.03 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     811.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     770.04 ms /     1 runs   (  770.04 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     772.09 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     815.01 ms /     1 runs   (  815.01 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     815.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     748.26 ms /     1 runs   (  748.26 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     749.51 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     735.79 ms /     1 runs   (  735.79 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     736.26 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11111.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.99 ms /     1 runs   (  772.99 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     773.79 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     770.85 ms /     1 runs   (  770.85 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     771.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     766.27 ms /     1 runs   (  766.27 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     767.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18518.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.62 ms /     1 runs   (  762.62 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     763.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     775.06 ms /     1 runs   (  775.06 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     758.44 ms /     1 runs   (  758.44 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     759.76 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.07 ms /     1 runs   (  789.07 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     790.09 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     781.17 ms /     1 runs   (  781.17 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     781.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     745.71 ms /     1 runs   (  745.71 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     746.34 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     766.05 ms /     1 runs   (  766.05 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     767.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     795.56 ms /     1 runs   (  795.56 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     797.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     754.67 ms /     1 runs   (  754.67 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     755.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     745.67 ms /     1 runs   (  745.67 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     746.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     801.34 ms /     1 runs   (  801.34 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     802.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     785.62 ms /     1 runs   (  785.62 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     786.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     759.88 ms /     1 runs   (  759.88 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     761.80 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.86 ms /     1 runs   (  764.86 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     765.92 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12345.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     771.94 ms /     1 runs   (  771.94 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     772.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     748.43 ms /     1 runs   (  748.43 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     748.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     744.83 ms /     1 runs   (  744.83 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     747.86 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     699.32 ms /     1 runs   (  699.32 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =     702.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     782.11 ms /     1 runs   (  782.11 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     783.14 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  9433.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     747.08 ms /     1 runs   (  747.08 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     748.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     749.82 ms /     1 runs   (  749.82 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     751.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     780.26 ms /     1 runs   (  780.26 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     782.14 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.97 ms /     1 runs   (  760.97 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     801.24 ms /     1 runs   (  801.24 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     801.51 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     817.73 ms /     1 runs   (  817.73 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     818.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     856.47 ms /     1 runs   (  856.47 ms per token,     1.17 tokens per second)\n",
      "llama_print_timings:       total time =     857.27 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     782.25 ms /     1 runs   (  782.25 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     782.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     790.65 ms /     1 runs   (  790.65 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     791.34 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.27 ms /     1 runs   (  760.27 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     761.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     744.48 ms /     1 runs   (  744.48 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     746.20 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     814.72 ms /     1 runs   (  814.72 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     815.19 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    1001.45 ms /     1 runs   ( 1001.45 ms per token,     1.00 tokens per second)\n",
      "llama_print_timings:       total time =    1002.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     962.37 ms /     1 runs   (  962.37 ms per token,     1.04 tokens per second)\n",
      "llama_print_timings:       total time =     963.32 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     800.75 ms /     1 runs   (  800.75 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     802.40 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10416.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     794.13 ms /     1 runs   (  794.13 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     796.84 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     768.93 ms /     1 runs   (  768.93 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     770.04 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     817.45 ms /     1 runs   (  817.45 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     818.14 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25641.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     796.02 ms /     1 runs   (  796.02 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     796.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     776.65 ms /     1 runs   (  776.65 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     777.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     805.62 ms /     1 runs   (  805.62 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     806.98 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     755.73 ms /     1 runs   (  755.73 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     756.80 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     749.15 ms /     1 runs   (  749.15 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     749.81 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     764.44 ms /     1 runs   (  764.44 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     765.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     747.32 ms /     1 runs   (  747.32 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     748.44 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     765.70 ms /     1 runs   (  765.70 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     767.25 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     770.68 ms /     1 runs   (  770.68 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     773.79 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     742.36 ms /     1 runs   (  742.36 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     743.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     784.88 ms /     1 runs   (  784.88 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     785.39 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     774.36 ms /     1 runs   (  774.36 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     778.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     757.15 ms /     1 runs   (  757.15 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     757.63 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     783.08 ms /     1 runs   (  783.08 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     784.22 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25641.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     769.37 ms /     1 runs   (  769.37 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     770.44 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     794.18 ms /     1 runs   (  794.18 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     796.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     727.57 ms /     1 runs   (  727.57 ms per token,     1.37 tokens per second)\n",
      "llama_print_timings:       total time =     728.27 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     768.55 ms /     1 runs   (  768.55 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     769.04 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.98 ms /     1 runs   (  772.98 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     773.86 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     760.44 ms /     1 runs   (  760.44 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     761.32 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     770.22 ms /     1 runs   (  770.22 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     771.73 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     745.36 ms /     1 runs   (  745.36 ms per token,     1.34 tokens per second)\n",
      "llama_print_timings:       total time =     746.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     778.75 ms /     1 runs   (  778.75 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     779.17 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     736.33 ms /     1 runs   (  736.33 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     737.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     752.00 ms /     1 runs   (  752.00 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     753.30 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     794.84 ms /     1 runs   (  794.84 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     795.70 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     817.50 ms /     1 runs   (  817.50 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     818.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     798.45 ms /     1 runs   (  798.45 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     799.61 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token,  9900.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     792.74 ms /     1 runs   (  792.74 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     794.02 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     779.12 ms /     1 runs   (  779.12 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     780.72 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     810.03 ms /     1 runs   (  810.03 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     811.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     781.50 ms /     1 runs   (  781.50 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     781.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20833.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     776.95 ms /     1 runs   (  776.95 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     777.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     820.33 ms /     1 runs   (  820.33 ms per token,     1.22 tokens per second)\n",
      "llama_print_timings:       total time =     821.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     768.36 ms /     1 runs   (  768.36 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     769.80 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  8849.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     989.70 ms /     1 runs   (  989.70 ms per token,     1.01 tokens per second)\n",
      "llama_print_timings:       total time =     992.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     930.34 ms /     1 runs   (  930.34 ms per token,     1.07 tokens per second)\n",
      "llama_print_timings:       total time =     931.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     863.43 ms /     1 runs   (  863.43 ms per token,     1.16 tokens per second)\n",
      "llama_print_timings:       total time =     867.33 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     815.16 ms /     1 runs   (  815.16 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     815.57 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     804.84 ms /     1 runs   (  804.84 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     805.63 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     759.66 ms /     1 runs   (  759.66 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     760.60 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     776.59 ms /     1 runs   (  776.59 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     777.52 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     753.87 ms /     1 runs   (  753.87 ms per token,     1.33 tokens per second)\n",
      "llama_print_timings:       total time =     756.74 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     769.44 ms /     1 runs   (  769.44 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     771.43 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     781.33 ms /     1 runs   (  781.33 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =     782.95 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     761.62 ms /     1 runs   (  761.62 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     762.46 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     762.14 ms /     1 runs   (  762.14 ms per token,     1.31 tokens per second)\n",
      "llama_print_timings:       total time =     763.00 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     791.23 ms /     1 runs   (  791.23 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     793.58 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     793.48 ms /     1 runs   (  793.48 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     795.66 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     759.36 ms /     1 runs   (  759.36 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     760.87 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     823.27 ms /     1 runs   (  823.27 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     824.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     809.11 ms /     1 runs   (  809.11 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     810.26 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     796.43 ms /     1 runs   (  796.43 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     796.88 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     774.15 ms /     1 runs   (  774.15 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     775.37 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     791.39 ms /     1 runs   (  791.39 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     792.42 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     787.48 ms /     1 runs   (  787.48 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     788.96 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     772.31 ms /     1 runs   (  772.31 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     773.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12345.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     792.84 ms /     1 runs   (  792.84 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     793.90 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     792.12 ms /     1 runs   (  792.12 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     793.09 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     735.43 ms /     1 runs   (  735.43 ms per token,     1.36 tokens per second)\n",
      "llama_print_timings:       total time =     736.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16129.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     795.23 ms /     1 runs   (  795.23 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     795.84 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     796.13 ms /     1 runs   (  796.13 ms per token,     1.26 tokens per second)\n",
      "llama_print_timings:       total time =     797.22 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25641.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     766.38 ms /     1 runs   (  766.38 ms per token,     1.30 tokens per second)\n",
      "llama_print_timings:       total time =     767.97 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     829.32 ms /     1 runs   (  829.32 ms per token,     1.21 tokens per second)\n",
      "llama_print_timings:       total time =     830.22 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     808.92 ms /     1 runs   (  808.92 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     809.51 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.05 ms /     1 runs   (  789.05 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     791.17 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     797.30 ms /     1 runs   (  797.30 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     799.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     807.35 ms /     1 runs   (  807.35 ms per token,     1.24 tokens per second)\n",
      "llama_print_timings:       total time =     808.61 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     775.84 ms /     1 runs   (  775.84 ms per token,     1.29 tokens per second)\n",
      "llama_print_timings:       total time =     778.11 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     800.20 ms /     1 runs   (  800.20 ms per token,     1.25 tokens per second)\n",
      "llama_print_timings:       total time =     801.16 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     789.07 ms /     1 runs   (  789.07 ms per token,     1.27 tokens per second)\n",
      "llama_print_timings:       total time =     789.92 ms /     1 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     14.102.161.98:0 - \"POST /generate/medusa HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      13.64 ms /   219 runs   (    0.06 ms per token, 16054.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  171585.69 ms /   219 runs   (  783.50 ms per token,     1.28 tokens per second)\n",
      "llama_print_timings:       total time =  171866.48 ms /   219 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     552.66 ms /     1 runs   (  552.66 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =     553.91 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     529.36 ms /     1 runs   (  529.36 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     529.79 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     534.58 ms /     1 runs   (  534.58 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =     534.90 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10869.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     534.95 ms /     1 runs   (  534.95 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =     535.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      44.70 ms /   679 runs   (    0.07 ms per token, 15189.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  470302.35 ms /   679 runs   (  692.64 ms per token,     1.44 tokens per second)\n",
      "llama_print_timings:       total time =  471724.43 ms /   679 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      13.12 ms /   218 runs   (    0.06 ms per token, 16622.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  122332.80 ms /   218 runs   (  561.16 ms per token,     1.78 tokens per second)\n",
      "llama_print_timings:       total time =  122585.31 ms /   218 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      12.91 ms /   217 runs   (    0.06 ms per token, 16812.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  121391.46 ms /   217 runs   (  559.41 ms per token,     1.79 tokens per second)\n",
      "llama_print_timings:       total time =  121650.08 ms /   217 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      13.81 ms /   216 runs   (    0.06 ms per token, 15639.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  122801.16 ms /   216 runs   (  568.52 ms per token,     1.76 tokens per second)\n",
      "llama_print_timings:       total time =  123078.00 ms /   216 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      43.97 ms /   678 runs   (    0.06 ms per token, 15418.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  395097.86 ms /   678 runs   (  582.74 ms per token,     1.72 tokens per second)\n",
      "llama_print_timings:       total time =  396449.04 ms /   678 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      12.74 ms /   215 runs   (    0.06 ms per token, 16873.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  121584.51 ms /   215 runs   (  565.51 ms per token,     1.77 tokens per second)\n",
      "llama_print_timings:       total time =  121826.94 ms /   215 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     538.06 ms /     1 runs   (  538.06 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =     538.83 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     540.47 ms /     1 runs   (  540.47 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =     542.88 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     616.74 ms /     1 runs   (  616.74 ms per token,     1.62 tokens per second)\n",
      "llama_print_timings:       total time =     616.85 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     738.11 ms /     1 runs   (  738.11 ms per token,     1.35 tokens per second)\n",
      "llama_print_timings:       total time =     738.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      12.41 ms /   214 runs   (    0.06 ms per token, 17239.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  118466.57 ms /   214 runs   (  553.58 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =  118706.39 ms /   214 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      13.08 ms /   213 runs   (    0.06 ms per token, 16286.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  120326.60 ms /   213 runs   (  564.91 ms per token,     1.77 tokens per second)\n",
      "llama_print_timings:       total time =  120583.95 ms /   213 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      39.72 ms /   677 runs   (    0.06 ms per token, 17042.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  391892.75 ms /   677 runs   (  578.87 ms per token,     1.73 tokens per second)\n",
      "llama_print_timings:       total time =  393180.24 ms /   677 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.12 ms /     1 runs   (    0.12 ms per token,  8196.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     552.62 ms /     1 runs   (  552.62 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =     553.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     526.82 ms /     1 runs   (  526.82 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     528.00 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11494.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     544.44 ms /     1 runs   (  544.44 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =     545.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     572.87 ms /     1 runs   (  572.87 ms per token,     1.75 tokens per second)\n",
      "llama_print_timings:       total time =     574.32 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      13.40 ms /   212 runs   (    0.06 ms per token, 15825.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  119720.43 ms /   212 runs   (  564.72 ms per token,     1.77 tokens per second)\n",
      "llama_print_timings:       total time =  119953.06 ms /   212 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      15.16 ms /   211 runs   (    0.07 ms per token, 13917.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  118470.61 ms /   211 runs   (  561.47 ms per token,     1.78 tokens per second)\n",
      "llama_print_timings:       total time =  118714.58 ms /   211 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 23809.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     548.58 ms /     1 runs   (  548.58 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =     548.99 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 23809.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     535.19 ms /     1 runs   (  535.19 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =     536.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     585.98 ms /     1 runs   (  585.98 ms per token,     1.71 tokens per second)\n",
      "llama_print_timings:       total time =     586.22 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     564.78 ms /     1 runs   (  564.78 ms per token,     1.77 tokens per second)\n",
      "llama_print_timings:       total time =     565.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /   210 runs   (    0.06 ms per token, 17291.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  114572.99 ms /   210 runs   (  545.59 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =  114806.35 ms /   210 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    96 runs   (    0.06 ms per token, 17201.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   51482.48 ms /    96 runs   (  536.28 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =   51577.30 ms /    96 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      40.25 ms /   676 runs   (    0.06 ms per token, 16796.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  384634.31 ms /   676 runs   (  568.99 ms per token,     1.76 tokens per second)\n",
      "llama_print_timings:       total time =  385906.74 ms /   676 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.25 ms /    94 runs   (    0.06 ms per token, 17901.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   50111.14 ms /    94 runs   (  533.10 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =   50196.17 ms /    94 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    93 runs   (    0.05 ms per token, 19076.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   48713.78 ms /    93 runs   (  523.80 ms per token,     1.91 tokens per second)\n",
      "llama_print_timings:       total time =   48787.20 ms /    93 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19607.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     518.59 ms /     1 runs   (  518.59 ms per token,     1.93 tokens per second)\n",
      "llama_print_timings:       total time =     520.12 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25641.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     525.32 ms /     1 runs   (  525.32 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     527.36 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 26315.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     525.45 ms /     1 runs   (  525.45 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     525.76 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 27777.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     517.24 ms /     1 runs   (  517.24 ms per token,     1.93 tokens per second)\n",
      "llama_print_timings:       total time =     517.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    92 runs   (    0.05 ms per token, 18748.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   48576.61 ms /    92 runs   (  528.01 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =   48655.44 ms /    92 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.13 ms /    91 runs   (    0.06 ms per token, 17735.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   48005.21 ms /    91 runs   (  527.53 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =   48092.01 ms /    91 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    90 runs   (    0.06 ms per token, 15853.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   48438.81 ms /    90 runs   (  538.21 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =   48522.31 ms /    90 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    89 runs   (    0.06 ms per token, 16710.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   47680.50 ms /    89 runs   (  535.74 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =   47758.98 ms /    89 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     523.22 ms /     1 runs   (  523.22 ms per token,     1.91 tokens per second)\n",
      "llama_print_timings:       total time =     523.60 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     542.34 ms /     1 runs   (  542.34 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =     543.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     534.04 ms /     1 runs   (  534.04 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =     535.14 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     522.98 ms /     1 runs   (  522.98 ms per token,     1.91 tokens per second)\n",
      "llama_print_timings:       total time =     524.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    88 runs   (    0.06 ms per token, 16362.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   48619.46 ms /    88 runs   (  552.49 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =   48703.24 ms /    88 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    87 runs   (    0.06 ms per token, 16847.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   47391.86 ms /    87 runs   (  544.73 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   47468.98 ms /    87 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      39.71 ms /   675 runs   (    0.06 ms per token, 16999.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  378731.65 ms /   675 runs   (  561.08 ms per token,     1.78 tokens per second)\n",
      "llama_print_timings:       total time =  379983.62 ms /   675 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.45 ms /    86 runs   (    0.06 ms per token, 15788.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   47030.07 ms /    86 runs   (  546.86 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =   47113.27 ms /    86 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.12 ms /    85 runs   (    0.06 ms per token, 16585.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   45811.46 ms /    85 runs   (  538.96 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =   45889.49 ms /    85 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10416.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     508.71 ms /     1 runs   (  508.71 ms per token,     1.97 tokens per second)\n",
      "llama_print_timings:       total time =     509.67 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     531.53 ms /     1 runs   (  531.53 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =     532.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 23809.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     534.17 ms /     1 runs   (  534.17 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =     534.36 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 23255.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     510.74 ms /     1 runs   (  510.74 ms per token,     1.96 tokens per second)\n",
      "llama_print_timings:       total time =     511.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /    84 runs   (    0.06 ms per token, 17459.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   45600.37 ms /    84 runs   (  542.86 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   45679.94 ms /    84 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    83 runs   (    0.06 ms per token, 17663.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   45085.86 ms /    83 runs   (  543.20 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   45157.16 ms /    83 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.06 ms /    82 runs   (    0.06 ms per token, 16208.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   44657.44 ms /    82 runs   (  544.60 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   44735.88 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    81 runs   (    0.06 ms per token, 16493.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   44402.93 ms /    81 runs   (  548.18 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =   44477.28 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     525.63 ms /     1 runs   (  525.63 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     526.60 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12048.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     539.73 ms /     1 runs   (  539.73 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =     540.36 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 13157.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     532.86 ms /     1 runs   (  532.86 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =     533.45 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.12 ms /     1 runs   (    0.12 ms per token,  8064.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     547.91 ms /     1 runs   (  547.91 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =     550.89 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    82 runs   (    0.06 ms per token, 16882.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   44461.78 ms /    82 runs   (  542.22 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   44540.61 ms /    82 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       5.13 ms /    81 runs   (    0.06 ms per token, 15774.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   44258.84 ms /    81 runs   (  546.41 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =   44335.39 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    80 runs   (    0.08 ms per token, 13123.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   42873.56 ms /    80 runs   (  535.92 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =   42949.83 ms /    80 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      40.46 ms /   674 runs   (    0.06 ms per token, 16659.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  381652.68 ms /   674 runs   (  566.25 ms per token,     1.77 tokens per second)\n",
      "llama_print_timings:       total time =  382911.99 ms /   674 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    79 runs   (    0.06 ms per token, 16352.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   42716.24 ms /    79 runs   (  540.71 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =   42785.88 ms /    79 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     500.60 ms /     1 runs   (  500.60 ms per token,     2.00 tokens per second)\n",
      "llama_print_timings:       total time =     502.73 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     544.37 ms /     1 runs   (  544.37 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =     545.02 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 18867.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     504.25 ms /     1 runs   (  504.25 ms per token,     1.98 tokens per second)\n",
      "llama_print_timings:       total time =     505.17 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     546.55 ms /     1 runs   (  546.55 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =     547.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /    61 runs   (    0.06 ms per token, 17101.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   33097.03 ms /    61 runs   (  542.57 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   33150.03 ms /    61 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    60 runs   (    0.06 ms per token, 16835.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   32539.63 ms /    60 runs   (  542.33 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   32591.96 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    59 runs   (    0.06 ms per token, 16770.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   32235.25 ms /    59 runs   (  546.36 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =   32290.54 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /    58 runs   (    0.06 ms per token, 17303.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   31905.03 ms /    58 runs   (  550.09 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =   31954.05 ms /    58 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  9433.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     522.70 ms /     1 runs   (  522.70 ms per token,     1.91 tokens per second)\n",
      "llama_print_timings:       total time =     523.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     529.70 ms /     1 runs   (  529.70 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     530.02 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 11904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     526.68 ms /     1 runs   (  526.68 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     528.10 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     538.89 ms /     1 runs   (  538.89 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =     539.31 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /    57 runs   (    0.06 ms per token, 16691.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   31122.92 ms /    57 runs   (  546.02 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =   31174.90 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /    56 runs   (    0.06 ms per token, 17114.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   30676.75 ms /    56 runs   (  547.80 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =   30724.82 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /    55 runs   (    0.06 ms per token, 17747.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   30277.33 ms /    55 runs   (  550.50 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =   30326.53 ms /    55 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    54 runs   (    0.06 ms per token, 17329.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   29520.68 ms /    54 runs   (  546.68 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =   29568.86 ms /    54 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     546.38 ms /     1 runs   (  546.38 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =     547.22 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20408.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     593.47 ms /     1 runs   (  593.47 ms per token,     1.68 tokens per second)\n",
      "llama_print_timings:       total time =     594.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     549.07 ms /     1 runs   (  549.07 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =     549.53 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     591.47 ms /     1 runs   (  591.47 ms per token,     1.69 tokens per second)\n",
      "llama_print_timings:       total time =     592.50 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    53 runs   (    0.06 ms per token, 16454.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   29023.53 ms /    53 runs   (  547.61 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =   29074.03 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    52 runs   (    0.06 ms per token, 16434.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   28756.86 ms /    52 runs   (  553.02 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =   28804.55 ms /    52 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /    51 runs   (    0.06 ms per token, 16267.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   28111.84 ms /    51 runs   (  551.21 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =   28158.59 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      40.48 ms /   673 runs   (    0.06 ms per token, 16625.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  386049.05 ms /   673 runs   (  573.62 ms per token,     1.74 tokens per second)\n",
      "llama_print_timings:       total time =  387352.89 ms /   673 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     515.41 ms /     1 runs   (  515.41 ms per token,     1.94 tokens per second)\n",
      "llama_print_timings:       total time =     516.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     525.66 ms /     1 runs   (  525.66 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     526.34 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     557.95 ms /     1 runs   (  557.95 ms per token,     1.79 tokens per second)\n",
      "llama_print_timings:       total time =     558.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     539.85 ms /     1 runs   (  539.85 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =     540.24 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /    50 runs   (    0.06 ms per token, 17053.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   27218.96 ms /    50 runs   (  544.38 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   27262.22 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     548.12 ms /     1 runs   (  548.12 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =     549.47 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     514.17 ms /     1 runs   (  514.17 ms per token,     1.94 tokens per second)\n",
      "llama_print_timings:       total time =     514.76 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15873.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     547.10 ms /     1 runs   (  547.10 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =     547.97 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     555.25 ms /     1 runs   (  555.25 ms per token,     1.80 tokens per second)\n",
      "llama_print_timings:       total time =     556.40 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    49 runs   (    0.06 ms per token, 17174.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   28413.90 ms /    49 runs   (  579.88 ms per token,     1.72 tokens per second)\n",
      "llama_print_timings:       total time =   28453.84 ms /    49 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /    48 runs   (    0.06 ms per token, 16410.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   26060.92 ms /    48 runs   (  542.94 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   26102.92 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /    47 runs   (    0.06 ms per token, 17420.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   25894.25 ms /    47 runs   (  550.94 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =   25936.33 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    46 runs   (    0.06 ms per token, 16364.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   24955.36 ms /    46 runs   (  542.51 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   25003.13 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11363.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     528.15 ms /     1 runs   (  528.15 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     529.64 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     524.85 ms /     1 runs   (  524.85 ms per token,     1.91 tokens per second)\n",
      "llama_print_timings:       total time =     525.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     517.41 ms /     1 runs   (  517.41 ms per token,     1.93 tokens per second)\n",
      "llama_print_timings:       total time =     518.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.11 ms /     1 runs   (    0.11 ms per token,  9345.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     522.06 ms /     1 runs   (  522.06 ms per token,     1.92 tokens per second)\n",
      "llama_print_timings:       total time =     524.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    43 runs   (    0.06 ms per token, 16226.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   23355.79 ms /    43 runs   (  543.16 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   23395.49 ms /    43 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.45 ms /    42 runs   (    0.06 ms per token, 17114.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   22682.63 ms /    42 runs   (  540.06 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =   22718.54 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /    41 runs   (    0.06 ms per token, 16865.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   22534.63 ms /    41 runs   (  549.63 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =   22571.12 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /    40 runs   (    0.06 ms per token, 16687.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   21719.79 ms /    40 runs   (  542.99 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =   21753.24 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     525.68 ms /     1 runs   (  525.68 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     526.44 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     539.74 ms /     1 runs   (  539.74 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =     540.90 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11363.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     515.88 ms /     1 runs   (  515.88 ms per token,     1.94 tokens per second)\n",
      "llama_print_timings:       total time =     516.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     558.11 ms /     1 runs   (  558.11 ms per token,     1.79 tokens per second)\n",
      "llama_print_timings:       total time =     559.23 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /    39 runs   (    0.06 ms per token, 17687.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   21047.63 ms /    39 runs   (  539.68 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =   21078.73 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    38 runs   (    0.06 ms per token, 17055.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   20943.88 ms /    38 runs   (  551.15 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =   20975.77 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    37 runs   (    0.06 ms per token, 16879.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   20561.99 ms /    37 runs   (  555.73 ms per token,     1.80 tokens per second)\n",
      "llama_print_timings:       total time =   20593.81 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /    36 runs   (    0.10 ms per token, 10256.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   19720.32 ms /    36 runs   (  547.79 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =   19752.72 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     529.84 ms /     1 runs   (  529.84 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     530.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.14 ms /     1 runs   (    0.14 ms per token,  7092.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     526.57 ms /     1 runs   (  526.57 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     527.77 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     577.09 ms /     1 runs   (  577.09 ms per token,     1.73 tokens per second)\n",
      "llama_print_timings:       total time =     577.89 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     533.05 ms /     1 runs   (  533.05 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =     534.18 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /    10 runs   (    0.05 ms per token, 20080.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    5720.42 ms /    10 runs   (  572.04 ms per token,     1.75 tokens per second)\n",
      "llama_print_timings:       total time =    5727.34 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     9 runs   (    0.05 ms per token, 18789.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    4821.78 ms /     9 runs   (  535.75 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =    4828.00 ms /     9 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     8 runs   (    0.07 ms per token, 14362.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    4256.98 ms /     8 runs   (  532.12 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =    4264.24 ms /     8 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     7 runs   (    0.06 ms per token, 16055.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    3895.89 ms /     7 runs   (  556.56 ms per token,     1.80 tokens per second)\n",
      "llama_print_timings:       total time =    3900.71 ms /     7 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     604.12 ms /     1 runs   (  604.12 ms per token,     1.66 tokens per second)\n",
      "llama_print_timings:       total time =     604.52 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14084.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     597.28 ms /     1 runs   (  597.28 ms per token,     1.67 tokens per second)\n",
      "llama_print_timings:       total time =     598.35 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17543.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     572.09 ms /     1 runs   (  572.09 ms per token,     1.75 tokens per second)\n",
      "llama_print_timings:       total time =     573.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     548.46 ms /     1 runs   (  548.46 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =     551.09 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     6 runs   (    0.06 ms per token, 17804.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    3252.76 ms /     6 runs   (  542.13 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =    3257.52 ms /     6 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     5 runs   (    0.06 ms per token, 17064.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    2654.68 ms /     5 runs   (  530.94 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =    2658.56 ms /     5 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     4 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    2139.73 ms /     4 runs   (  534.93 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =    2142.60 ms /     4 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     3 runs   (    0.07 ms per token, 14218.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    1614.11 ms /     3 runs   (  538.04 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    1616.31 ms /     3 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 27027.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     526.66 ms /     1 runs   (  526.66 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     527.34 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     521.50 ms /     1 runs   (  521.50 ms per token,     1.92 tokens per second)\n",
      "llama_print_timings:       total time =     522.07 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     553.37 ms /     1 runs   (  553.37 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =     554.20 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13513.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     530.61 ms /     1 runs   (  530.61 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =     531.36 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     2 runs   (    0.05 ms per token, 19417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    1060.33 ms /     2 runs   (  530.16 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =    1061.28 ms /     2 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     620.36 ms /     1 runs   (  620.36 ms per token,     1.61 tokens per second)\n",
      "llama_print_timings:       total time =     621.73 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     600.66 ms /     1 runs   (  600.66 ms per token,     1.66 tokens per second)\n",
      "llama_print_timings:       total time =     601.01 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     576.62 ms /     1 runs   (  576.62 ms per token,     1.73 tokens per second)\n",
      "llama_print_timings:       total time =     577.13 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     535.14 ms /     1 runs   (  535.14 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =     535.64 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     522.35 ms /     1 runs   (  522.35 ms per token,     1.91 tokens per second)\n",
      "llama_print_timings:       total time =     523.04 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     531.76 ms /     1 runs   (  531.76 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =     532.53 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     507.50 ms /     1 runs   (  507.50 ms per token,     1.97 tokens per second)\n",
      "llama_print_timings:       total time =     508.27 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /    22 runs   (    0.06 ms per token, 16591.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   11734.76 ms /    22 runs   (  533.40 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =   11751.28 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /    21 runs   (    0.05 ms per token, 18213.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   11139.45 ms /    21 runs   (  530.45 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =   11156.87 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /    20 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   11166.86 ms /    20 runs   (  558.34 ms per token,     1.79 tokens per second)\n",
      "llama_print_timings:       total time =   11182.24 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    19 runs   (    0.06 ms per token, 16695.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   10217.85 ms /    19 runs   (  537.78 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =   10234.57 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     563.37 ms /     1 runs   (  563.37 ms per token,     1.78 tokens per second)\n",
      "llama_print_timings:       total time =     564.25 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 19230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     511.17 ms /     1 runs   (  511.17 ms per token,     1.96 tokens per second)\n",
      "llama_print_timings:       total time =     511.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     539.12 ms /     1 runs   (  539.12 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =     539.37 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12987.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     538.16 ms /     1 runs   (  538.16 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =     539.15 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      39.05 ms /   672 runs   (    0.06 ms per token, 17209.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  386709.78 ms /   672 runs   (  575.46 ms per token,     1.74 tokens per second)\n",
      "llama_print_timings:       total time =  387990.96 ms /   672 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /    18 runs   (    0.06 ms per token, 17681.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    9627.11 ms /    18 runs   (  534.84 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =    9641.51 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /    22 runs   (    0.06 ms per token, 17254.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   12263.99 ms /    22 runs   (  557.45 ms per token,     1.79 tokens per second)\n",
      "llama_print_timings:       total time =   12280.77 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    21 runs   (    0.06 ms per token, 17647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   11116.65 ms /    21 runs   (  529.36 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =   11134.17 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /    20 runs   (    0.06 ms per token, 17316.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   10706.00 ms /    20 runs   (  535.30 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =   10723.66 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14492.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     578.55 ms /     1 runs   (  578.55 ms per token,     1.73 tokens per second)\n",
      "llama_print_timings:       total time =     579.51 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     537.11 ms /     1 runs   (  537.11 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =     538.49 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15151.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     512.14 ms /     1 runs   (  512.14 ms per token,     1.95 tokens per second)\n",
      "llama_print_timings:       total time =     512.89 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14925.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     538.27 ms /     1 runs   (  538.27 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =     538.62 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /    19 runs   (    0.06 ms per token, 17288.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =   10761.48 ms /    19 runs   (  566.39 ms per token,     1.77 tokens per second)\n",
      "llama_print_timings:       total time =   10778.92 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [1398]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import logging\n",
    "import asyncio\n",
    "from typing import List, Dict, Optional\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from pyngrok import ngrok\n",
    "import time\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from threading import Lock\n",
    "from contextlib import asynccontextmanager\n",
    "import uvicorn\n",
    "import os\n",
    "\n",
    "# For notebook environments\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Import Medusa components from the repository\n",
    "from medusa.model.medusa_model import MedusaModel\n",
    "from medusa.model.medusa_choices import mc_sim_7b_63\n",
    "from medusa.model.utils import generate_medusa_buffers\n",
    "from medusa.model.kv_cache import initialize_past_key_values\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define request and response models\n",
    "class GenerationRequest(BaseModel):\n",
    "    prompt: str\n",
    "    max_length: int = 512\n",
    "    temperature: float = 0.7\n",
    "    posterior_threshold: float = 0.09\n",
    "    posterior_alpha: float = 0.3\n",
    "\n",
    "class GenerationResponse(BaseModel):\n",
    "    text: str\n",
    "    generation_time: float\n",
    "    tokens_generated: int\n",
    "    tokens_per_second: float\n",
    "    speedup_factor: Optional[float] = None\n",
    "    acceptance_rate: Optional[float] = None\n",
    "\n",
    "class ComparisonResponse(BaseModel):\n",
    "    normal: GenerationResponse\n",
    "    medusa: GenerationResponse\n",
    "    speedup: float\n",
    "\n",
    "class MedusaLlamaCppManager:\n",
    "    \"\"\"\n",
    "    Manager class that combines llama.cpp with Medusa for speculative decoding.\n",
    "    This class loads the model, sets up Medusa buffers, and provides text generation.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str,\n",
    "        medusa_num_heads: int = 4,\n",
    "        n_ctx: int = 2048,\n",
    "        n_batch: int = 512,\n",
    "        n_threads: int = 8\n",
    "    ):\n",
    "        self.logger = logging.getLogger(\"MedusaLlamaCppManager\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.medusa_num_heads = medusa_num_heads\n",
    "        self.model_lock = Lock()  # For thread safety\n",
    "\n",
    "        # Check if model exists\n",
    "        if not os.path.exists(model_path):\n",
    "            self.logger.error(f\"Model file not found at {model_path}\")\n",
    "            raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "        # Load compiled model using llama.cpp backend\n",
    "        self.logger.info(f\"Loading model from {model_path}...\")\n",
    "        self.llama_model = Llama(\n",
    "            model_path=model_path,\n",
    "            n_ctx=n_ctx,\n",
    "            n_batch=n_batch,\n",
    "            n_threads=n_threads,\n",
    "            n_gpu_layers=-1,  # Use all GPU layers\n",
    "            verbose=True  # For debugging\n",
    "        )\n",
    "        self.logger.info(f\"Loaded GGUF model from {model_path}\")\n",
    "\n",
    "        # Initialize Medusa components\n",
    "        self.medusa_buffers = self._initialize_medusa_buffers()\n",
    "        self.logger.info(f\"Initialized Medusa buffers with {medusa_num_heads} heads\")\n",
    "\n",
    "        # Calculate baseline speed for later comparison\n",
    "        self._baseline_tokens_per_second = self._calculate_baseline_speed()\n",
    "        self.logger.info(f\"Baseline generation speed: {self._baseline_tokens_per_second:.2f} tokens/second\")\n",
    "\n",
    "    def _initialize_medusa_buffers(self) -> Dict:\n",
    "        \"\"\"Initialize Medusa buffers for speculative decoding.\"\"\"\n",
    "        # Create buffers for Medusa\n",
    "        tree_indices = torch.zeros((self.medusa_num_heads, 2), dtype=torch.long)\n",
    "        medusa_attn_mask = torch.ones((self.medusa_num_heads + 1, self.medusa_num_heads + 1), dtype=torch.bool)\n",
    "        medusa_attn_mask = torch.triu(medusa_attn_mask, diagonal=1)\n",
    "        medusa_position_ids = torch.arange(self.medusa_num_heads, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"tree_indices\": tree_indices,\n",
    "            \"medusa_attn_mask\": medusa_attn_mask,\n",
    "            \"medusa_position_ids\": medusa_position_ids,\n",
    "            \"retrieve_indices\": None  # Will be set during generation\n",
    "        }\n",
    "\n",
    "    def _calculate_baseline_speed(self) -> float:\n",
    "        \"\"\"Calculate baseline generation speed without Medusa.\"\"\"\n",
    "        prompt = \"Once upon a time\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = self.llama_model(prompt, max_tokens=20, temperature=0.7)\n",
    "\n",
    "        if response and 'choices' in response:\n",
    "            generated_text = response['choices'][0]['text']\n",
    "            tokens = len(generated_text.split())\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            if elapsed_time > 0 and tokens > 0:\n",
    "                tokens_per_second = tokens / elapsed_time\n",
    "                self.logger.info(f\"Baseline generation speed: {tokens_per_second:.2f} tokens/second\")\n",
    "                return tokens_per_second\n",
    "\n",
    "        # Default value if calculation fails\n",
    "        return 5.0\n",
    "\n",
    "    def generate_normal(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        max_length: int = 512,\n",
    "        temperature: float = 0.7\n",
    "    ) -> Dict:\n",
    "        \"\"\"Generate text using standard approach (no Medusa)\"\"\"\n",
    "        with self.model_lock:  # Ensure thread safety\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # For better reliability, use straightforward generation\n",
    "            self.logger.info(f\"Normal generation with prompt: {prompt[:50]}...\")\n",
    "            \n",
    "            try:\n",
    "                # Generate text using llama.cpp directly\n",
    "                response = self.llama_model(\n",
    "                    prompt,\n",
    "                    max_tokens=min(max_length, 100),  # Cap max tokens for reliability\n",
    "                    temperature=temperature,\n",
    "                    echo=False\n",
    "                )\n",
    "                \n",
    "                if not response or 'choices' not in response:\n",
    "                    self.logger.error(\"No response from model\")\n",
    "                    return {\n",
    "                        \"text\": \"Error: No response from model\",\n",
    "                        \"generation_time\": time.time() - start_time,\n",
    "                        \"tokens_generated\": 0,\n",
    "                        \"tokens_per_second\": 0,\n",
    "                        \"speedup_factor\": 0\n",
    "                    }\n",
    "                \n",
    "                generated_text = response['choices'][0]['text']\n",
    "                tokens_generated = len(generated_text.split())\n",
    "                \n",
    "                elapsed_time = time.time() - start_time\n",
    "                tokens_per_second = tokens_generated / elapsed_time if elapsed_time > 0 else 0\n",
    "                \n",
    "                self.logger.info(f\"Normal generation: {tokens_generated} tokens in {elapsed_time:.2f} seconds\")\n",
    "                self.logger.info(f\"Normal generation speed: {tokens_per_second:.2f} tokens/second\")\n",
    "                \n",
    "                return {\n",
    "                    \"text\": generated_text,\n",
    "                    \"generation_time\": elapsed_time,\n",
    "                    \"tokens_generated\": tokens_generated,\n",
    "                    \"tokens_per_second\": tokens_per_second,\n",
    "                    \"speedup_factor\": 1.0  # No speedup for normal generation\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in normal generation: {str(e)}\")\n",
    "                return {\n",
    "                    \"text\": f\"Error: {str(e)}\",\n",
    "                    \"generation_time\": time.time() - start_time,\n",
    "                    \"tokens_generated\": 0,\n",
    "                    \"tokens_per_second\": 0,\n",
    "                    \"speedup_factor\": 0\n",
    "                }\n",
    "\n",
    "    def generate_medusa(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        max_length: int = 512,\n",
    "        temperature: float = 0.7,\n",
    "        posterior_threshold: float = 0.09,\n",
    "        posterior_alpha: float = 0.3\n",
    "    ) -> Dict:\n",
    "        \"\"\"Generate text using Medusa speculative decoding\"\"\"\n",
    "        with self.model_lock:  # Ensure thread safety\n",
    "            start_time = time.time()\n",
    "            \n",
    "            self.logger.info(f\"Medusa generation with prompt: {prompt[:50]}...\")\n",
    "            \n",
    "            try:\n",
    "                input_text = prompt\n",
    "                generated_text = \"\"\n",
    "                tokens_generated = 0\n",
    "                draft_tokens_generated = 0\n",
    "                accepted_tokens = 0\n",
    "                \n",
    "                # Add safeguard \n",
    "                max_iterations = min(max_length, 100)\n",
    "                \n",
    "                for _ in range(max_iterations):\n",
    "                    # Generate base token and draft tokens\n",
    "                    base_token, drafts = self._generate_drafts(input_text, temperature)\n",
    "                    \n",
    "                    if not base_token:\n",
    "                        self.logger.warning(\"No base token generated, ending generation\")\n",
    "                        break\n",
    "                    \n",
    "                    # Count drafts\n",
    "                    draft_tokens_generated += len(drafts) + 1  # Base + drafts\n",
    "                    \n",
    "                    # Verify drafts\n",
    "                    accept_count, accepted_tokens_list = self._verify_drafts(\n",
    "                        input_text, \n",
    "                        [base_token] + drafts, \n",
    "                        temperature, \n",
    "                        posterior_threshold,\n",
    "                        posterior_alpha\n",
    "                    )\n",
    "                    \n",
    "                    # Update accepted count\n",
    "                    accepted_tokens += accept_count\n",
    "                    \n",
    "                    # Use accepted tokens or fallback to base token\n",
    "                    if accept_count > 0:\n",
    "                        token_text = ''.join(accepted_tokens_list)\n",
    "                        input_text += token_text\n",
    "                        generated_text += token_text\n",
    "                        tokens_generated += accept_count\n",
    "                    else:\n",
    "                        input_text += base_token\n",
    "                        generated_text += base_token\n",
    "                        tokens_generated += 1\n",
    "                    \n",
    "                    # Log progress periodically\n",
    "                    if tokens_generated % 20 == 0:\n",
    "                        self.logger.info(f\"Generated {tokens_generated} tokens so far\")\n",
    "                \n",
    "                elapsed_time = time.time() - start_time\n",
    "                tokens_per_second = tokens_generated / elapsed_time if elapsed_time > 0 else 0\n",
    "                acceptance_rate = (accepted_tokens / draft_tokens_generated * 100) if draft_tokens_generated > 0 else 0\n",
    "                \n",
    "                self.logger.info(f\"Medusa generation: {tokens_generated} tokens in {elapsed_time:.2f} seconds\")\n",
    "                self.logger.info(f\"Medusa speed: {tokens_per_second:.2f} tokens/second\")\n",
    "                self.logger.info(f\"Acceptance rate: {acceptance_rate:.2f}%\")\n",
    "                \n",
    "                return {\n",
    "                    \"text\": generated_text,\n",
    "                    \"generation_time\": elapsed_time,\n",
    "                    \"tokens_generated\": tokens_generated,\n",
    "                    \"tokens_per_second\": tokens_per_second,\n",
    "                    \"speedup_factor\": tokens_per_second / self._baseline_tokens_per_second,\n",
    "                    \"acceptance_rate\": acceptance_rate\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in Medusa generation: {str(e)}\")\n",
    "                return {\n",
    "                    \"text\": f\"Error: {str(e)}\",\n",
    "                    \"generation_time\": time.time() - start_time,\n",
    "                    \"tokens_generated\": 0,\n",
    "                    \"tokens_per_second\": 0,\n",
    "                    \"speedup_factor\": 0,\n",
    "                    \"acceptance_rate\": 0\n",
    "                }\n",
    "\n",
    "    def _generate_drafts(self, context: str, temperature: float) -> tuple:\n",
    "        \"\"\"Generate base and draft tokens following the Medusa pattern\"\"\"\n",
    "        try:\n",
    "            # Get the base token\n",
    "            base_response = self.llama_model(\n",
    "                context,\n",
    "                max_tokens=1,\n",
    "                temperature=temperature,\n",
    "                echo=False\n",
    "            )\n",
    "            \n",
    "            if not base_response or 'choices' not in base_response:\n",
    "                return \"\", []\n",
    "                \n",
    "            base_token = base_response['choices'][0]['text']\n",
    "            \n",
    "            # Generate draft tokens in tree structure (continuation of base token)\n",
    "            drafts = []\n",
    "            current_context = context + base_token\n",
    "            \n",
    "            # Generate drafts following tree structure\n",
    "            for i in range(min(self.medusa_num_heads - 1, 3)):  # Limit to 3 drafts max for performance\n",
    "                try:\n",
    "                    draft_response = self.llama_model(\n",
    "                        current_context,\n",
    "                        max_tokens=1,\n",
    "                        temperature=temperature,\n",
    "                        echo=False\n",
    "                    )\n",
    "                    \n",
    "                    if draft_response and 'choices' in draft_response:\n",
    "                        draft_token = draft_response['choices'][0]['text']\n",
    "                        drafts.append(draft_token)\n",
    "                        current_context += draft_token\n",
    "                    else:\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error generating draft {i}: {str(e)}\")\n",
    "                    break\n",
    "            \n",
    "            return base_token, drafts\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in draft generation: {str(e)}\")\n",
    "            return \"\", []\n",
    "\n",
    "    def _verify_drafts(\n",
    "        self,\n",
    "        context: str,\n",
    "        drafts: List[str],\n",
    "        temperature: float,\n",
    "        threshold: float,\n",
    "        alpha: float\n",
    "    ) -> tuple:\n",
    "        \"\"\"Verify draft tokens and return accepted ones\"\"\"\n",
    "        if not drafts:\n",
    "            return 0, []\n",
    "            \n",
    "        accepted_drafts = []\n",
    "        current_context = context\n",
    "        \n",
    "        for i, draft in enumerate(drafts):\n",
    "            try:\n",
    "                # For the base token (first draft), always accept\n",
    "                if i == 0:\n",
    "                    accepted_drafts.append(draft)\n",
    "                    current_context += draft\n",
    "                    continue\n",
    "                \n",
    "                # For subsequent tokens, verify\n",
    "                verify_response = self.llama_model(\n",
    "                    current_context,\n",
    "                    max_tokens=1,\n",
    "                    temperature=0,  # Use zero temperature for deterministic output\n",
    "                    echo=False\n",
    "                )\n",
    "                \n",
    "                # Simple verification: if the model generates the same token, it's good\n",
    "                if verify_response and 'choices' in verify_response:\n",
    "                    predicted = verify_response['choices'][0]['text']\n",
    "                    \n",
    "                    # Calculate simple score (1.0 if perfect match, 0.0 otherwise)\n",
    "                    score = 1.0 if predicted == draft else 0.0\n",
    "                    \n",
    "                    # Apply threshold\n",
    "                    if score >= threshold:\n",
    "                        accepted_drafts.append(draft)\n",
    "                        current_context += draft\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in draft verification: {str(e)}\")\n",
    "                break\n",
    "        \n",
    "        return len(accepted_drafts), accepted_drafts\n",
    "\n",
    "# Global variables for model manager\n",
    "model_manager = None\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Lifespan context for startup and shutdown actions.\"\"\"\n",
    "    global model_manager\n",
    "\n",
    "    logger.info(\"Initializing model manager...\")\n",
    "    try:\n",
    "        model_path = \"/kaggle/input/vicuna-1/gguf/default/1/vicuna-7b-v1.3-F16_KM.gguf\"\n",
    "        model_manager = MedusaLlamaCppManager(\n",
    "            model_path=model_path,\n",
    "            medusa_num_heads=4,\n",
    "            n_ctx=2048,\n",
    "            n_batch=512,\n",
    "            n_threads=8\n",
    "        )\n",
    "        logger.info(\"Model manager initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    try:\n",
    "        # Set up ngrok tunnel for external access\n",
    "        ngrok_tunnel = ngrok.connect(8000)\n",
    "        logger.info(f\"Ngrok tunnel established at: {ngrok_tunnel.public_url}\")\n",
    "        print(f\"Public URL: {ngrok_tunnel.public_url}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to establish ngrok tunnel: {str(e)}\")\n",
    "\n",
    "    yield\n",
    "\n",
    "    # Shutdown procedures can be added here\n",
    "    logger.info(\"Shutting down server and cleaning up resources.\")\n",
    "\n",
    "# Initialize FastAPI app with lifespan context\n",
    "app = FastAPI(\n",
    "    title=\"Medusa LLM Service\",\n",
    "    description=\"Language model service with both standard and Medusa speculative decoding\",\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "# Normal generation endpoint\n",
    "@app.post(\"/generate/normal\", response_model=GenerationResponse)\n",
    "async def generate_normal(request: GenerationRequest):\n",
    "    \"\"\"Generate text using normal decoding (without Medusa)\"\"\"\n",
    "    try:\n",
    "        if model_manager is None:\n",
    "            raise HTTPException(status_code=503, detail=\"Model not initialized\")\n",
    "        \n",
    "        logger.info(f\"Processing normal generation request: {request.prompt[:50]}...\")\n",
    "        \n",
    "        # Use asyncio.to_thread to avoid blocking the event loop\n",
    "        result = await asyncio.to_thread(\n",
    "            model_manager.generate_normal,\n",
    "            prompt=request.prompt,\n",
    "            max_length=min(request.max_length, 100),\n",
    "            temperature=request.temperature\n",
    "        )\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            raise HTTPException(status_code=500, detail=result[\"error\"])\n",
    "            \n",
    "        return GenerationResponse(\n",
    "            text=result[\"text\"],\n",
    "            generation_time=result[\"generation_time\"],\n",
    "            tokens_generated=result[\"tokens_generated\"],\n",
    "            tokens_per_second=result[\"tokens_per_second\"],\n",
    "            speedup_factor=result[\"speedup_factor\"]\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in normal generation endpoint: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Medusa generation endpoint\n",
    "@app.post(\"/generate/medusa\", response_model=GenerationResponse)\n",
    "async def generate_medusa(request: GenerationRequest):\n",
    "    \"\"\"Generate text using Medusa speculative decoding\"\"\"\n",
    "    try:\n",
    "        if model_manager is None:\n",
    "            raise HTTPException(status_code=503, detail=\"Model not initialized\")\n",
    "        \n",
    "        logger.info(f\"Processing Medusa generation request: {request.prompt[:50]}...\")\n",
    "        \n",
    "        # Use asyncio.to_thread to avoid blocking the event loop\n",
    "        result = await asyncio.to_thread(\n",
    "            model_manager.generate_medusa,\n",
    "            prompt=request.prompt,\n",
    "            max_length=min(request.max_length, 100),\n",
    "            temperature=request.temperature,\n",
    "            posterior_threshold=request.posterior_threshold,\n",
    "            posterior_alpha=request.posterior_alpha\n",
    "        )\n",
    "        \n",
    "        if \"error\" in result:\n",
    "            raise HTTPException(status_code=500, detail=result[\"error\"])\n",
    "            \n",
    "        return GenerationResponse(\n",
    "            text=result[\"text\"],\n",
    "            generation_time=result[\"generation_time\"],\n",
    "            tokens_generated=result[\"tokens_generated\"],\n",
    "            tokens_per_second=result[\"tokens_per_second\"],\n",
    "            speedup_factor=result[\"speedup_factor\"],\n",
    "            acceptance_rate=result[\"acceptance_rate\"]\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in Medusa generation endpoint: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Comparison endpoint - runs both methods and compares\n",
    "@app.post(\"/compare\", response_model=ComparisonResponse)\n",
    "async def compare_generation_methods(request: GenerationRequest):\n",
    "    \"\"\"Compare normal and Medusa generation methods\"\"\"\n",
    "    try:\n",
    "        if model_manager is None:\n",
    "            raise HTTPException(status_code=503, detail=\"Model not initialized\")\n",
    "        \n",
    "        logger.info(f\"Running comparison with prompt: {request.prompt[:50]}...\")\n",
    "        \n",
    "        # Run normal generation\n",
    "        normal_result = await asyncio.to_thread(\n",
    "            model_manager.generate_normal,\n",
    "            prompt=request.prompt,\n",
    "            max_length=min(request.max_length, 100),\n",
    "            temperature=request.temperature\n",
    "        )\n",
    "        \n",
    "        # Run Medusa generation\n",
    "        medusa_result = await asyncio.to_thread(\n",
    "            model_manager.generate_medusa,\n",
    "            prompt=request.prompt,\n",
    "            max_length=min(request.max_length, 100),\n",
    "            temperature=request.temperature,\n",
    "            posterior_threshold=request.posterior_threshold,\n",
    "            posterior_alpha=request.posterior_alpha\n",
    "        )\n",
    "        \n",
    "        # Calculate speedup\n",
    "        normal_speed = normal_result[\"tokens_per_second\"]\n",
    "        medusa_speed = medusa_result[\"tokens_per_second\"]\n",
    "        speedup = medusa_speed / normal_speed if normal_speed > 0 else 0\n",
    "        \n",
    "        # Create response\n",
    "        normal_response = GenerationResponse(\n",
    "            text=normal_result[\"text\"],\n",
    "            generation_time=normal_result[\"generation_time\"],\n",
    "            tokens_generated=normal_result[\"tokens_generated\"],\n",
    "            tokens_per_second=normal_result[\"tokens_per_second\"],\n",
    "            speedup_factor=normal_result[\"speedup_factor\"]\n",
    "        )\n",
    "        \n",
    "        medusa_response = GenerationResponse(\n",
    "            text=medusa_result[\"text\"],\n",
    "            generation_time=medusa_result[\"generation_time\"],\n",
    "            tokens_generated=medusa_result[\"tokens_generated\"],\n",
    "            tokens_per_second=medusa_result[\"tokens_per_second\"],\n",
    "            speedup_factor=medusa_result[\"speedup_factor\"],\n",
    "            acceptance_rate=medusa_result[\"acceptance_rate\"]\n",
    "        )\n",
    "        \n",
    "        return ComparisonResponse(\n",
    "            normal=normal_response,\n",
    "            medusa=medusa_response,\n",
    "            speedup=speedup\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in comparison endpoint: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Health check endpoint\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Check if the service is healthy\"\"\"\n",
    "    # Also check if model is loaded\n",
    "    model_status = \"loaded\" if model_manager is not None else \"not loaded\"\n",
    "    return {\n",
    "        \"status\": \"healthy\", \n",
    "        \"model\": model_status,\n",
    "        \"device\": model_manager.device if model_manager else \"unknown\"\n",
    "    }\n",
    "\n",
    "# Function to start the server\n",
    "async def start_server():\n",
    "    \"\"\"Start the FastAPI server\"\"\"\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()\n",
    "\n",
    "# Entry point for running the file directly\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Check if running in a notebook environment\n",
    "        if 'google.colab' in globals() or 'kaggle_secrets' in globals():\n",
    "            # Running in notebook (Colab or Kaggle)\n",
    "            nest_asyncio.apply()\n",
    "            asyncio.run(start_server())\n",
    "        else:\n",
    "            # Standard Python environment\n",
    "            import uvicorn\n",
    "            uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error starting server: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test this implementation with the following curl commands:\n",
    "\n",
    "\n",
    "```json\n",
    "# Normal generation\n",
    "curl -X POST \"https://your-ngrok-url/generate/normal\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"prompt\": \"Once upon a time\", \"max_length\": 50, \"temperature\": 0.7}'\n",
    "\n",
    "# Medusa generation\n",
    "curl -X POST \"https://your-ngrok-url/generate/medusa\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"prompt\": \"Once upon a time\", \"max_length\": 50, \"temperature\": 0.7}'\n",
    "\n",
    "# Compare both methods\n",
    "curl -X POST \"https://your-ngrok-url/compare\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"prompt\": \"Once upon a time\", \"max_length\": 50, \"temperature\": 0.7}'\n",
    "```"
   ]
  },
  {
   "attachments": {
    "3afcc22c-1b33-42f7-86eb-a4183867ae82.png": {
     "image/png": "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"
    },
    "4214feaf-bb85-43a5-bf1f-4b7d8c8a51f9.png": {
     "image/png": "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"
    },
    "60069889-eb48-4920-adce-bb585adbccb0.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output tested\n",
    "\n",
    "#### test1\n",
    "\n",
    "**Request**\n",
    "```\n",
    "curl -X POST \"https://dadf-35-194-149-242.ngrok-free.app/compare\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"prompt\": \"Once upon a time\",\n",
    "    \"max_length\": 50\n",
    "  }'\n",
    "```\n",
    "**Response**\n",
    "```\n",
    "{\n",
    "  \"normal\": {\n",
    "    \"text\": \", a long, long time ago, in a small village nestled in the foothills of the majestic Himalayas, there lived a young girl named Mala. Mala was a curious and adventurous child, always eager\",\n",
    "    \"generation_time\": 37.465,\n",
    "    \"tokens_generated\": 34,\n",
    "    \"tokens_per_second\": 0.9075,\n",
    "    \"speedup_factor\": 1.0,\n",
    "    \"acceptance_rate\": null\n",
    "  },\n",
    "  \"medusa\": {\n",
    "    \"text\": \", in a far-off land, there was a kind and gentle woman who lived in a small village. She was known for her kindness, her wisdom, and her love of nature. She spent her days tending to her garden, helping her neighbors, and teaching the children of the village.\\nThe woman was deeply spiritual, and she spent many hours in prayer and meditation, seeking guidance from the divine. She believed that the natural world was a reflection of the divine, and that every plant, animal, and stone had a spirit that needed to be respected and honored.\\nOne day, as the woman was walking in the forest, she came\",\n",
    "    \"generation_time\": 249.927,\n",
    "    \"tokens_generated\": 136,\n",
    "    \"tokens_per_second\": 0.5442,\n",
    "    \"speedup_factor\": 0.5123,\n",
    "    \"acceptance_rate\": 68.0\n",
    "  },\n",
    "  \"speedup\": 0.5996\n",
    "}\n",
    "```\n",
    "![image.png](attachment:3afcc22c-1b33-42f7-86eb-a4183867ae82.png)\n",
    "\n",
    "\n",
    "\n",
    "#### Test 2\n",
    "**Request** \n",
    "```\n",
    "curl -X POST \"https://dadf-35-194-149-242.ngrok-free.app/generate/normal\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"prompt\": \"Once upon a time\",\n",
    "    \"max_length\": 50\n",
    "  }'\n",
    "\n",
    "```\n",
    "**Response**\n",
    "```\n",
    "{\n",
    "  \"text\": \", a young girl named Lily was born in a small village. She lived a happy life with her parents and siblings, and she loved to help her mother in the kitchen. Lily' 123Movies Movies\",\n",
    "  \"generation_time\": 40.3927,\n",
    "  \"tokens_generated\": 35,\n",
    "  \"tokens_per_second\": 0.8665,\n",
    "  \"speedup_factor\": 1.0,\n",
    "  \"acceptance_rate\": null\n",
    "}\n",
    "```\n",
    "![image.png](attachment:4214feaf-bb85-43a5-bf1f-4b7d8c8a51f9.png)\n",
    "\n",
    "\n",
    "\n",
    "#### Test 3\n",
    "\n",
    "**Request**\n",
    "```\n",
    "curl -X POST \"https://dadf-35-194-149-242.ngrok-free.app/generate/medusa\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"prompt\": \"Once upon a time\",\n",
    "    \"max_length\": 50\n",
    "  }'\n",
    "\n",
    "```\n",
    "\n",
    "**response**\n",
    "\n",
    "```\n",
    "{\n",
    "  \"text\": \", in a small village, there lived a kind, old man named John. John was loved by everyone in the village because he was always ready to help those in need. He had a large garden where he grew all kinds of fruits and vegetables. John was known for his delicious apple pies and fruit preserves. People from far and wide came to buy his produce and taste his pies and preserves.\\nOne day, a group of travelers passed through the village. They were on their way to a distant land and were hungry. They asked John if he had any food to sell. John told them that he had plenty of food, but he only sold it to people who could pay him in gold or silver coins. The travelers had no coins, but they\",\n",
    "  \"generation_time\": 263.546,\n",
    "  \"tokens_generated\": 163,\n",
    "  \"tokens_per_second\": 0.6185,\n",
    "  \"speedup_factor\": 0.5823,\n",
    "  \"acceptance_rate\": 81.5\n",
    "}\n",
    "```\n",
    "\n",
    "![image.png](attachment:60069889-eb48-4920-adce-bb585adbccb0.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T12:24:14.083233Z",
     "iopub.status.busy": "2025-03-28T12:24:14.082881Z",
     "iopub.status.idle": "2025-03-28T12:24:19.783343Z",
     "shell.execute_reply": "2025-03-28T12:24:19.782282Z",
     "shell.execute_reply.started": "2025-03-28T12:24:14.083197Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /    15 runs   (    0.07 ms per token, 15045.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    8083.41 ms /    15 runs   (  538.89 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    8100.10 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "ERROR:    Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 699, in lifespan\n",
      "    await receive()\n",
      "GeneratorExit\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Comparison:\n",
      "\n",
      "             Metric Normal Medusa\n",
      "  Tokens per Second 0.8870 0.5814\n",
      "Generation Time (s)  38.93 256.74\n",
      "   Tokens Generated   34.5  149.5\n",
      "     Speedup Factor   1.00 0.6554\n",
      "Acceptance Rate (%)    N/A   74.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /    14 runs   (    0.06 ms per token, 17283.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    8381.83 ms /    14 runs   (  598.70 ms per token,     1.67 tokens per second)\n",
      "llama_print_timings:       total time =    8430.47 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /    15 runs   (    0.05 ms per token, 19059.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    8301.87 ms /    15 runs   (  553.46 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =    8315.14 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     600.86 ms /     1 runs   (  600.86 ms per token,     1.66 tokens per second)\n",
      "llama_print_timings:       total time =     601.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     509.99 ms /     1 runs   (  509.99 ms per token,     1.96 tokens per second)\n",
      "llama_print_timings:       total time =     510.41 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 27027.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     505.86 ms /     1 runs   (  505.86 ms per token,     1.98 tokens per second)\n",
      "llama_print_timings:       total time =     506.21 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     526.55 ms /     1 runs   (  526.55 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     527.59 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /    14 runs   (    0.06 ms per token, 17925.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    7478.39 ms /    14 runs   (  534.17 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =    7489.73 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /    13 runs   (    0.06 ms per token, 17881.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    6949.18 ms /    13 runs   (  534.55 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =    6960.33 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /    12 runs   (    0.05 ms per token, 18838.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    6455.75 ms /    12 runs   (  537.98 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    6465.62 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /    11 runs   (    0.06 ms per token, 17684.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    5777.88 ms /    11 runs   (  525.26 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =    5788.30 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     543.38 ms /     1 runs   (  543.38 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =     545.82 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20833.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     524.47 ms /     1 runs   (  524.47 ms per token,     1.91 tokens per second)\n",
      "llama_print_timings:       total time =     525.39 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11627.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     551.63 ms /     1 runs   (  551.63 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =     552.48 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     595.71 ms /     1 runs   (  595.71 ms per token,     1.68 tokens per second)\n",
      "llama_print_timings:       total time =     598.36 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.57 ms /    10 runs   (    0.06 ms per token, 17667.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    5901.24 ms /    10 runs   (  590.12 ms per token,     1.69 tokens per second)\n",
      "llama_print_timings:       total time =    5911.41 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.51 ms /     9 runs   (    0.06 ms per token, 17578.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    4844.36 ms /     9 runs   (  538.26 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    4851.86 ms /     9 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     8 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    4294.16 ms /     8 runs   (  536.77 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    4301.55 ms /     8 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     7 runs   (    0.05 ms per token, 18469.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    3755.13 ms /     7 runs   (  536.45 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    3761.48 ms /     7 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     528.96 ms /     1 runs   (  528.96 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     529.63 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 20000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     533.79 ms /     1 runs   (  533.79 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =     535.45 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 27027.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     527.40 ms /     1 runs   (  527.40 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     527.78 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 24390.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     515.98 ms /     1 runs   (  515.98 ms per token,     1.94 tokens per second)\n",
      "llama_print_timings:       total time =     516.99 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.37 ms /     6 runs   (    0.06 ms per token, 16393.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    3217.67 ms /     6 runs   (  536.28 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    3223.03 ms /     6 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     5 runs   (    0.05 ms per token, 19379.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    2685.31 ms /     5 runs   (  537.06 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    2688.82 ms /     5 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     4 runs   (    0.05 ms per token, 18779.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    2143.57 ms /     4 runs   (  535.89 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =    2147.79 ms /     4 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /    11 runs   (    0.07 ms per token, 14285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    6307.50 ms /    11 runs   (  573.41 ms per token,     1.74 tokens per second)\n",
      "llama_print_timings:       total time =    6316.52 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     526.88 ms /     1 runs   (  526.88 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     528.19 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 28571.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     542.62 ms /     1 runs   (  542.62 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =     543.56 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token, 10000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     533.71 ms /     1 runs   (  533.71 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =     534.68 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 18181.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     553.37 ms /     1 runs   (  553.37 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =     554.12 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /    10 runs   (    0.05 ms per token, 18416.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    5372.45 ms /    10 runs   (  537.24 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    5379.57 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.57 ms /     9 runs   (    0.06 ms per token, 15679.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    4846.65 ms /     9 runs   (  538.52 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =    4853.80 ms /     9 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.52 ms /     8 runs   (    0.07 ms per token, 15384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    4268.20 ms /     8 runs   (  533.53 ms per token,     1.87 tokens per second)\n",
      "llama_print_timings:       total time =    4276.90 ms /     8 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     7 runs   (    0.06 ms per token, 16355.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    3693.62 ms /     7 runs   (  527.66 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =    3699.14 ms /     7 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token,  9900.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     542.78 ms /     1 runs   (  542.78 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =     543.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 15625.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     547.31 ms /     1 runs   (  547.31 ms per token,     1.83 tokens per second)\n",
      "llama_print_timings:       total time =     548.28 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     527.98 ms /     1 runs   (  527.98 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     528.35 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     538.76 ms /     1 runs   (  538.76 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =     539.02 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.05 ms /     1 runs   (    0.05 ms per token, 21276.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     549.53 ms /     1 runs   (  549.53 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =     550.55 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 24390.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     531.52 ms /     1 runs   (  531.52 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =     532.08 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     540.77 ms /     1 runs   (  540.77 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =     541.38 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 17241.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     525.31 ms /     1 runs   (  525.31 ms per token,     1.90 tokens per second)\n",
      "llama_print_timings:       total time =     525.78 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 25000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     532.84 ms /     1 runs   (  532.84 ms per token,     1.88 tokens per second)\n",
      "llama_print_timings:       total time =     533.51 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11111.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     584.95 ms /     1 runs   (  584.95 ms per token,     1.71 tokens per second)\n",
      "llama_print_timings:       total time =     585.60 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 22727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     541.75 ms /     1 runs   (  541.75 ms per token,     1.85 tokens per second)\n",
      "llama_print_timings:       total time =     543.78 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12345.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     536.84 ms /     1 runs   (  536.84 ms per token,     1.86 tokens per second)\n",
      "llama_print_timings:       total time =     537.42 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     5 runs   (    0.06 ms per token, 15432.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =    4257.43 ms /     5 runs   (  851.49 ms per token,     1.17 tokens per second)\n",
      "llama_print_timings:       total time =    4262.17 ms /     5 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 11494.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     813.95 ms /     1 runs   (  813.95 ms per token,     1.23 tokens per second)\n",
      "llama_print_timings:       total time =     814.69 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.09 ms /     1 runs   (    0.09 ms per token, 10638.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     701.75 ms /     1 runs   (  701.75 ms per token,     1.43 tokens per second)\n",
      "llama_print_timings:       total time =     702.77 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12820.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     758.84 ms /     1 runs   (  758.84 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =     759.75 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 24390.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     706.33 ms /     1 runs   (  706.33 ms per token,     1.42 tokens per second)\n",
      "llama_print_timings:       total time =     707.09 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1950.08 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /   150 runs   (    0.07 ms per token, 13952.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1629.60 ms /     4 tokens (  407.40 ms per token,     2.45 tokens per second)\n",
      "llama_print_timings:        eval time =  113088.24 ms /   149 runs   (  758.98 ms per token,     1.32 tokens per second)\n",
      "llama_print_timings:       total time =  114895.14 ms /   153 tokens\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      40.50 ms /   671 runs   (    0.06 ms per token, 16568.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  410748.70 ms /   671 runs   (  612.14 ms per token,     1.63 tokens per second)\n",
      "llama_print_timings:       total time =  412020.24 ms /   671 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      26.27 ms /   442 runs   (    0.06 ms per token, 16825.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  273610.22 ms /   442 runs   (  619.03 ms per token,     1.62 tokens per second)\n",
      "llama_print_timings:       total time =  274260.11 ms /   442 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      25.83 ms /   441 runs   (    0.06 ms per token, 17073.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  242462.20 ms /   441 runs   (  549.80 ms per token,     1.82 tokens per second)\n",
      "llama_print_timings:       total time =  243182.38 ms /   441 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      39.39 ms /   670 runs   (    0.06 ms per token, 17008.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  376846.69 ms /   670 runs   (  562.46 ms per token,     1.78 tokens per second)\n",
      "llama_print_timings:       total time =  378145.56 ms /   670 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      27.93 ms /   440 runs   (    0.06 ms per token, 15755.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  243805.27 ms /   440 runs   (  554.10 ms per token,     1.80 tokens per second)\n",
      "llama_print_timings:       total time =  244519.22 ms /   440 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =      40.61 ms /   669 runs   (    0.06 ms per token, 16472.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  377769.50 ms /   669 runs   (  564.68 ms per token,     1.77 tokens per second)\n",
      "llama_print_timings:       total time =  379117.33 ms /   669 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.06 ms /     1 runs   (    0.06 ms per token, 16666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     542.57 ms /     1 runs   (  542.57 ms per token,     1.84 tokens per second)\n",
      "llama_print_timings:       total time =     544.80 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.04 ms /     1 runs   (    0.04 ms per token, 23255.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     518.08 ms /     1 runs   (  518.08 ms per token,     1.93 tokens per second)\n",
      "llama_print_timings:       total time =     518.86 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12658.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     518.46 ms /     1 runs   (  518.46 ms per token,     1.93 tokens per second)\n",
      "llama_print_timings:       total time =     519.06 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1256.18 ms\n",
      "llama_print_timings:      sample time =       0.08 ms /     1 runs   (    0.08 ms per token, 12195.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     530.26 ms /     1 runs   (  530.26 ms per token,     1.89 tokens per second)\n",
      "llama_print_timings:       total time =     530.74 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =      27.12 ms /   439 runs   (    0.06 ms per token, 16190.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =  242731.10 ms /   439 runs   (  552.92 ms per token,     1.81 tokens per second)\n",
      "llama_print_timings:       total time =  243430.40 ms /   439 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13698.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     524.18 ms /     1 runs   (  524.18 ms per token,     1.91 tokens per second)\n",
      "llama_print_timings:       total time =     524.46 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 13888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     652.71 ms /     1 runs   (  652.71 ms per token,     1.53 tokens per second)\n",
      "llama_print_timings:       total time =     653.44 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.10 ms /     1 runs   (    0.10 ms per token,  9900.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     683.40 ms /     1 runs   (  683.40 ms per token,     1.46 tokens per second)\n",
      "llama_print_timings:       total time =     684.05 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     886.03 ms\n",
      "llama_print_timings:      sample time =       0.07 ms /     1 runs   (    0.07 ms per token, 14705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\n",
      "llama_print_timings:        eval time =     578.83 ms /     1 runs   (  578.83 ms per token,     1.73 tokens per second)\n",
      "llama_print_timings:       total time =     579.14 ms /     1 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Test data\n",
    "test_data = {\n",
    "    \"Test 1\": {\n",
    "        \"normal\": {\n",
    "            \"text_length\": 34,\n",
    "            \"generation_time\": 37.465,\n",
    "            \"tokens_per_second\": 0.9075,\n",
    "            \"speedup_factor\": 1.0,\n",
    "        },\n",
    "        \"medusa\": {\n",
    "            \"text_length\": 136,\n",
    "            \"generation_time\": 249.927,\n",
    "            \"tokens_per_second\": 0.5442,\n",
    "            \"speedup_factor\": 0.5123,\n",
    "            \"acceptance_rate\": 68.0\n",
    "        }\n",
    "    },\n",
    "    \"Test 2\": {\n",
    "        \"normal\": {\n",
    "            \"text_length\": 35,\n",
    "            \"generation_time\": 40.3927,\n",
    "            \"tokens_per_second\": 0.8665,\n",
    "            \"speedup_factor\": 1.0,\n",
    "        }\n",
    "    },\n",
    "    \"Test 3\": {\n",
    "        \"medusa\": {\n",
    "            \"text_length\": 163,\n",
    "            \"generation_time\": 263.546,\n",
    "            \"tokens_per_second\": 0.6185,\n",
    "            \"speedup_factor\": 0.5823,\n",
    "            \"acceptance_rate\": 81.5\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Organize data for plotting\n",
    "normal_tps = [test_data[\"Test 1\"][\"normal\"][\"tokens_per_second\"], \n",
    "              test_data[\"Test 2\"][\"normal\"][\"tokens_per_second\"]]\n",
    "normal_time = [test_data[\"Test 1\"][\"normal\"][\"generation_time\"], \n",
    "               test_data[\"Test 2\"][\"normal\"][\"generation_time\"]]\n",
    "normal_tokens = [test_data[\"Test 1\"][\"normal\"][\"text_length\"], \n",
    "                 test_data[\"Test 2\"][\"normal\"][\"text_length\"]]\n",
    "\n",
    "medusa_tps = [test_data[\"Test 1\"][\"medusa\"][\"tokens_per_second\"], \n",
    "              test_data[\"Test 3\"][\"medusa\"][\"tokens_per_second\"]]\n",
    "medusa_time = [test_data[\"Test 1\"][\"medusa\"][\"generation_time\"], \n",
    "               test_data[\"Test 3\"][\"medusa\"][\"generation_time\"]]\n",
    "medusa_tokens = [test_data[\"Test 1\"][\"medusa\"][\"text_length\"], \n",
    "                 test_data[\"Test 3\"][\"medusa\"][\"text_length\"]]\n",
    "medusa_acceptance = [test_data[\"Test 1\"][\"medusa\"][\"acceptance_rate\"], \n",
    "                     test_data[\"Test 3\"][\"medusa\"][\"acceptance_rate\"]]\n",
    "\n",
    "# Calculate averages\n",
    "avg_normal_tps = np.mean(normal_tps)\n",
    "avg_medusa_tps = np.mean(medusa_tps)\n",
    "avg_normal_time = np.mean(normal_time)\n",
    "avg_medusa_time = np.mean(medusa_time)\n",
    "avg_normal_tokens = np.mean(normal_tokens)\n",
    "avg_medusa_tokens = np.mean(medusa_tokens)\n",
    "avg_medusa_acceptance = np.mean(medusa_acceptance)\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Comparison: Normal vs. Medusa Text Generation', fontsize=16)\n",
    "\n",
    "# 1. Tokens per Second Comparison\n",
    "axs[0, 0].bar(['Normal', 'Medusa'], [avg_normal_tps, avg_medusa_tps], color=['#3498db', '#e74c3c'])\n",
    "axs[0, 0].set_title('Average Tokens per Second')\n",
    "axs[0, 0].set_ylabel('Tokens/second')\n",
    "for i, v in enumerate([avg_normal_tps, avg_medusa_tps]):\n",
    "    axs[0, 0].text(i, v + 0.05, f\"{v:.4f}\", ha='center')\n",
    "\n",
    "# 2. Generation Time Comparison\n",
    "axs[0, 1].bar(['Normal', 'Medusa'], [avg_normal_time, avg_medusa_time], color=['#3498db', '#e74c3c'])\n",
    "axs[0, 1].set_title('Average Generation Time')\n",
    "axs[0, 1].set_ylabel('Seconds')\n",
    "for i, v in enumerate([avg_normal_time, avg_medusa_time]):\n",
    "    axs[0, 1].text(i, v + 5, f\"{v:.2f}s\", ha='center')\n",
    "\n",
    "# 3. Tokens Generated Comparison\n",
    "axs[1, 0].bar(['Normal', 'Medusa'], [avg_normal_tokens, avg_medusa_tokens], color=['#3498db', '#e74c3c'])\n",
    "axs[1, 0].set_title('Average Tokens Generated')\n",
    "axs[1, 0].set_ylabel('Number of tokens')\n",
    "for i, v in enumerate([avg_normal_tokens, avg_medusa_tokens]):\n",
    "    axs[1, 0].text(i, v + 5, f\"{v:.1f}\", ha='center')\n",
    "\n",
    "# 4. Speedup and Acceptance Rate\n",
    "ax4 = axs[1, 1]\n",
    "ax4.bar(0, avg_medusa_acceptance, color='#2ecc71', label='Acceptance Rate')\n",
    "ax4.set_xticks([0])\n",
    "ax4.set_xticklabels(['Medusa'])\n",
    "ax4.set_ylabel('Acceptance Rate (%)', color='#2ecc71')\n",
    "ax4.tick_params(axis='y', labelcolor='#2ecc71')\n",
    "ax4.set_title('Medusa Metrics')\n",
    "ax4.text(0, avg_medusa_acceptance + 3, f\"{avg_medusa_acceptance:.1f}%\", ha='center')\n",
    "\n",
    "# Add a second y-axis for speedup factor\n",
    "ax4_twin = ax4.twinx()\n",
    "speedup_factor = avg_medusa_tps / avg_normal_tps\n",
    "ax4_twin.bar(0.5, speedup_factor, color='#9b59b6', label='Speedup Factor')\n",
    "ax4_twin.set_ylabel('Speedup Factor', color='#9b59b6')\n",
    "ax4_twin.tick_params(axis='y', labelcolor='#9b59b6')\n",
    "ax4_twin.set_xticks([0.5])\n",
    "ax4_twin.set_xticklabels(['vs. Normal'])\n",
    "ax4_twin.text(0.5, speedup_factor + 0.05, f\"{speedup_factor:.4f}x\", ha='center')\n",
    "\n",
    "# Add efficiency metric table\n",
    "plt.figtext(0.5, 0.01, \n",
    "           f\"Efficiency Analysis:\\n\"\n",
    "           f\"Normal: {avg_normal_tokens:.1f} tokens in {avg_normal_time:.2f}s\\n\"\n",
    "           f\"Medusa: {avg_medusa_tokens:.1f} tokens in {avg_medusa_time:.2f}s\\n\"\n",
    "           f\"Medusa is {speedup_factor:.2f}x the speed of Normal generation\",\n",
    "           ha=\"center\", fontsize=12, bbox={\"facecolor\":\"orange\", \"alpha\":0.2, \"pad\":5})\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "plt.savefig('generation_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Detailed performance table\n",
    "data = {\n",
    "    'Metric': ['Tokens per Second', 'Generation Time (s)', 'Tokens Generated', 'Speedup Factor', 'Acceptance Rate (%)'],\n",
    "    'Normal': [f\"{avg_normal_tps:.4f}\", f\"{avg_normal_time:.2f}\", f\"{avg_normal_tokens:.1f}\", \"1.00\", \"N/A\"],\n",
    "    'Medusa': [f\"{avg_medusa_tps:.4f}\", f\"{avg_medusa_time:.2f}\", f\"{avg_medusa_tokens:.1f}\", \n",
    "              f\"{speedup_factor:.4f}\", f\"{avg_medusa_acceptance:.1f}\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\nPerformance Comparison:\\n\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Analysis of Results\n",
    "\n",
    "Based on the test results here's an analysis of the performance:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Tokens per Second (Speed)**:\n",
    "   - Normal generation: ~0.887 tokens/second\n",
    "   - Medusa generation: ~0.581 tokens/second\n",
    "   - Medusa is actually **slower** (about 65% of normal speed)\n",
    "\n",
    "2. **Generation Time**:\n",
    "   - Normal generation takes much less time (avg ~39 seconds)\n",
    "   - Medusa generation takes significantly longer (avg ~257 seconds)\n",
    "\n",
    "3. **Text Output Length**:\n",
    "   - Normal generation: ~34.5 tokens per request\n",
    "   - Medusa generation: ~149.5 tokens per request\n",
    "   - Medusa generates much more text per request\n",
    "\n",
    "4. **Acceptance Rate**:\n",
    "   - Medusa has a high acceptance rate (avg ~75%)\n",
    "   - This indicates good speculative performance\n",
    "\n",
    "5. **Efficiency**:\n",
    "   - Despite the high acceptance rate, Medusa is not delivering the expected speedup\n",
    "\n",
    "### Why Is Medusa Slower Despite High Acceptance Rate?\n",
    "\n",
    "This unexpected result suggests several possible issues:\n",
    "\n",
    "1. **Implementation Overhead**: Your Medusa implementation may have significant computational overhead that counteracts the theoretical benefits of speculative decoding.\n",
    "\n",
    "2. **Verification Cost**: The token verification process might be too expensive relative to the time saved.\n",
    "\n",
    "3. **Integration Issues**: The way Medusa is integrated with the llama.cpp model may be suboptimal, introducing latency.\n",
    "\n",
    "4. **Memory Management**: Handling multiple draft tokens might be causing memory pressure or cache inefficiencies.\n",
    "\n",
    "5. **Sequential Processing**: The implementation might be doing too much sequential processing rather than parallel computation.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "While Medusa shows promising acceptance rates (indicating good speculative performance), the current implementation is not translating this into actual speed improvements. The normal generation approach is currently faster in terms of tokens per second, though Medusa generates more content per request.\n",
    "\n",
    "For time-sensitive applications where response speed is critical, the normal generation approach is currently the better choice. However, Medusa may be beneficial for applications where generating longer, more comprehensive responses is more important than speed.\n",
    "\n",
    "A deeper investigation into the implementation details is needed to realize the theoretical benefits of Medusa's speculative decoding approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Analysis: Why Medusa Is Not Performing as Expected\n",
    "\n",
    "The high acceptance rate (68-80%) shows that the speculative decoding is conceptually working, but the implementation has significant overhead that counteracts the theoretical benefits.\n",
    "\n",
    "## Current Issues\n",
    "\n",
    "### 1. Serial Model Calls Instead of Parallel Processing\n",
    "\n",
    "```python\n",
    "def _generate_drafts(self, context: str, temperature: float) -> tuple:\n",
    "    # Get the base token - FIRST MODEL CALL\n",
    "    base_response = self.llama_model(context, max_tokens=1, temperature=temperature, echo=False)\n",
    "    # ...\n",
    "    # Generate drafts following tree structure\n",
    "    for i in range(min(self.medusa_num_heads - 1, 3)):\n",
    "        # ADDITIONAL SEQUENTIAL MODEL CALLS\n",
    "        draft_response = self.llama_model(current_context, max_tokens=1, temperature=temperature, echo=False)\n",
    "        # ...\n",
    "```\n",
    "\n",
    "**Problem:** Every token generation requires a separate model call, creating massive overhead.\n",
    "\n",
    "### 2. Inefficient Draft Verification\n",
    "\n",
    "```python\n",
    "def _verify_drafts(self, context: str, drafts: List[str], temperature: float, threshold: float, alpha: float) -> tuple:\n",
    "    # ...\n",
    "    for i, draft in enumerate(drafts):\n",
    "        # For subsequent tokens, verify with ANOTHER MODEL CALL\n",
    "        verify_response = self.llama_model(current_context, max_tokens=1, temperature=0, echo=False)\n",
    "        # ...\n",
    "```\n",
    "\n",
    "**Problem:** Each draft verification requires another model call, causing additional overhead.\n",
    "\n",
    "### 3. No Proper KV-Cache Utilization\n",
    "\n",
    "implementation doesn't properly use the KV cache that makes speculative decoding efficient. In true Medusa implementations, you compute multiple tokens at once without regenerating the context.\n",
    "\n",
    "### 4. No Batch Processing of Draft Tokens\n",
    "\n",
    "The current implementation processes each token individually instead of batching operations, which is much less efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-28T10:16:35.285235Z",
     "iopub.status.busy": "2025-03-28T10:16:35.284883Z",
     "iopub.status.idle": "2025-03-28T10:16:35.578244Z",
     "shell.execute_reply": "2025-03-28T10:16:35.577145Z",
     "shell.execute_reply.started": "2025-03-28T10:16:35.285204Z"
    },
    "id": "pn415ae9Tiap",
    "outputId": "f1c011ef-d1ff-45bb-c217-31387479951e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken your auth token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WRhMXn5bmGh"
   },
   "outputs": [],
   "source": [
    "!ps aux | grep ngrok\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 281799,
     "modelInstanceId": 260644,
     "sourceId": 305494,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12b14e88bc09472897076dd6b8b62945": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2456245b43cb4d008e5a3cff9c473883": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29495f23ed974a9a9f54c06aee42708e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9f5552a9c0e42b09c96cb11bbad8b35",
      "placeholder": "​",
      "style": "IPY_MODEL_9bda68f535524c5997e0d11d81fae635",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "2a29e7d5d60e4230a53f302ea7794ff0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "35e12a72c3d140aab8a45a289db88155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "433c50d1f40442e39ab4e89756633ed2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6950c1233bb4bb588ccc86961e2e907",
      "placeholder": "​",
      "style": "IPY_MODEL_bf355ee0edf24dc18831d76ac9d39842",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "4d55d82c57c445739214a38419f638a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f2bedf81edd438db1e6c9a2aa41f232": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_433c50d1f40442e39ab4e89756633ed2",
       "IPY_MODEL_f7abca3d5824472e8efe63668cee5f8f",
       "IPY_MODEL_ec133885fe2b419286ae609f52efbf59",
       "IPY_MODEL_6b0f7d81472b4eaabb0325861c3e17d8",
       "IPY_MODEL_29495f23ed974a9a9f54c06aee42708e"
      ],
      "layout": "IPY_MODEL_b526e765ebfa410184392667c4ff7262"
     }
    },
    "661a5f9442c641a2ad4b84a466837d47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b0f7d81472b4eaabb0325861c3e17d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_12b14e88bc09472897076dd6b8b62945",
      "style": "IPY_MODEL_81941dffdc6e4c90b77fc6cb6506a626",
      "tooltip": ""
     }
    },
    "7c152aef3faa49e6a8370cb4a1d76856": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e0486bd82334c9786d4a682a7c867f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a57ce004e1cf4ac386a7f28e01c81cd1",
       "IPY_MODEL_d7f43223762d4fe29ad65e12aea985ed",
       "IPY_MODEL_d8c36726c50e4ec9b51ab9b95933c69b"
      ],
      "layout": "IPY_MODEL_2456245b43cb4d008e5a3cff9c473883"
     }
    },
    "81941dffdc6e4c90b77fc6cb6506a626": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "9657883fd54e47348635119813a8cfea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b1ecd205f02453b9a66535130d66185": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bda68f535524c5997e0d11d81fae635": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ffd8b1684444acd94294959214c3c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a57ce004e1cf4ac386a7f28e01c81cd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c152aef3faa49e6a8370cb4a1d76856",
      "placeholder": "​",
      "style": "IPY_MODEL_9657883fd54e47348635119813a8cfea",
      "value": "vicuna-7B-v1.3-F16.gguf: 100%"
     }
    },
    "a6950c1233bb4bb588ccc86961e2e907": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aabef08df1f3431db0a3b25a22c1a275": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b526e765ebfa410184392667c4ff7262": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "ba23535ee4f14566aa3a6319034b821a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf355ee0edf24dc18831d76ac9d39842": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7f43223762d4fe29ad65e12aea985ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba23535ee4f14566aa3a6319034b821a",
      "max": 13478105056,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a29e7d5d60e4230a53f302ea7794ff0",
      "value": 13478105056
     }
    },
    "d8c36726c50e4ec9b51ab9b95933c69b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_661a5f9442c641a2ad4b84a466837d47",
      "placeholder": "​",
      "style": "IPY_MODEL_aabef08df1f3431db0a3b25a22c1a275",
      "value": " 13.5G/13.5G [06:25&lt;00:00, 42.7MB/s]"
     }
    },
    "d9f5552a9c0e42b09c96cb11bbad8b35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec133885fe2b419286ae609f52efbf59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_4d55d82c57c445739214a38419f638a5",
      "style": "IPY_MODEL_9ffd8b1684444acd94294959214c3c28",
      "value": true
     }
    },
    "f7abca3d5824472e8efe63668cee5f8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_9b1ecd205f02453b9a66535130d66185",
      "placeholder": "​",
      "style": "IPY_MODEL_35e12a72c3d140aab8a45a289db88155",
      "value": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
